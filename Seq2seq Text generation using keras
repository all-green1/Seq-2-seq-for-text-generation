{"cells":[{"cell_type":"markdown","source":["### Introduction to Sequence-to-Sequence Models for Text Generation using Keras\n","\n","Sequence-to-sequence (Seq2Seq) models have been an important development in the field of Natural Language Processing (NLP), particularly for tasks involving text generation. These models, which were originally designed for machine translation, have proven their versatility in a wide range of applications, including chatbots, text summarization, and automated dialogue systems.\n","\n","Seq2Seq models have an architecture that comprises an encoder and a decoder. The encoder processes an input sequence and compresses its information into a context vector, which the decoder then uses to generate the output sequence. This approach allows the model to handle variable-length input and output sequences, making it highly adaptable to various NLP tasks.\n","\n","To implement Seq2Seq models, we rely on several key Python libraries:\n","- **Regex**: For text preprocessing, regular expressions (regex) are invaluable. They allow for efficient pattern matching and text manipulation, ensuring that the data fed into the model is clean and structured.\n","- **Numpy**: This fundamental library for numerical computing in Python provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n","- **Pandas**: For data manipulation and analysis, Pandas is essential. It offers data structures like DataFrames, which make it easy to handle and analyze structured data.\n","- **Keras**: Built on top of TensorFlow, Keras is a powerful and user-friendly deep learning library. It simplifies the process of building and training neural networks, including Seq2Seq models, by providing a high-level interface.\n","\n","This project will progress from dataset loading and preprocessing to the implementation of a Seq2Seq model for text generation using Keras. We'll start with text preprocessing using regex, Numpy, and Pandas, and then build and train our model with Keras. By the end, you will have a robust understanding of Seq2Seq models and how to leverage these powerful tools to create your own text generation applications.\n","\n","The text data used in this project are subtitles from Game of thrones TV series. This will be used to create a dialogue and further used to train the seq2seq model.\n"],"metadata":{"id":"FMCcmFsqC-Uh"},"id":"FMCcmFsqC-Uh"},{"cell_type":"code","source":["# Load the dataset from google drive\n","import json\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","season_1 = '/content/drive/MyDrive/Colab Notebooks/season1.json'\n","season_2 = '/content/drive/MyDrive/Colab Notebooks/season2.json'\n","season_3 = '/content/drive/MyDrive/Colab Notebooks/season3.json'\n","season_4 = '/content/drive/MyDrive/Colab Notebooks/season4.json'\n","season_5 = '/content/drive/MyDrive/Colab Notebooks/season5.json'\n","season_6 = '/content/drive/MyDrive/Colab Notebooks/season6.json'\n","season_7 = '/content/drive/MyDrive/Colab Notebooks/season7.json'\n","\n","# To prevent the notebook from crashing due to limited computational capacity, we'll only be  training the model with captions from two seasons\n","\n","seasons = [season_1, season_2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbMycj0xk5VM","executionInfo":{"status":"ok","timestamp":1720127987658,"user_tz":-120,"elapsed":29834,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"84ce62bc-f94a-47a8-fd64-7767ee208522"},"id":"jbMycj0xk5VM","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"id":"e88d84a6","metadata":{"id":"e88d84a6","executionInfo":{"status":"ok","timestamp":1720127991325,"user_tz":-120,"elapsed":2124,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"outputs":[],"source":["chat_data = []\n","for season in seasons:\n","  # read each file consequtively\n","\n","  with open(season,\"r\",encoding=\"utf-8\") as file:\n","    read_data=file.read()\n","    chat_data.append(read_data)\n","\n","# Safe everything into got_text\n","got_text = '\\n'.join(chat_data)"]},{"cell_type":"code","source":["chat_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1rHeZpjVywOukW1Ar5pXQ8E3S5Dl0-2OL"},"id":"Fi3K6TywVwjd","executionInfo":{"status":"ok","timestamp":1720120517542,"user_tz":-120,"elapsed":1741,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"f82bd0a2-1c80-461b-95bf-aa927172f286"},"id":"Fi3K6TywVwjd","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","execution_count":3,"id":"c87589f0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":990},"id":"c87589f0","executionInfo":{"status":"ok","timestamp":1720127998186,"user_tz":-120,"elapsed":501,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"224a39aa-a1f3-4f1d-d6e8-2c37572f9780"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Number                                               Text\n","5065     407                                               Shh.\n","5352     666                                           He will.\n","12965    578                     The world is built by killers.\n","1739     648  We've been capturing wildlings, more every month.\n","3313      72          - Where's Arya? - At her dancing lessons.\n","2441     613               But later when we started to fall...\n","9256      54     - I can't lose... - You'll die if she doesn't.\n","7847      54                              We'll just keep that.\n","7337      80       We have enough wheat for a five-year winter.\n","11776    204  Ha! The last time the scouts assured us of Sta...\n","11049    236  We can't make steel as good as yours, it's tru...\n","9866     531                            It looked like Stannis.\n","13394    388         To create strife between my sister and me.\n","3568     282                                       I deny them,\n","5735     410                      No, not your death, Khaleesi.\n","5439     144  He brought dishonour to our House, but he had ...\n","9595     288  He has a good mind for warfare, his men worshi...\n","12436    100                                 It's warm in here.\n","8484     433                 Dorne is the safest place for her.\n","11075     26                  They have no value to me missing.\n","1747     655                              and what lies beyond.\n","1839     738                                               Hup!\n","8892     211                    You've never married, have you?\n","9485     189                     I don't hang them for treason.\n","8362     323                                    Matrimony, huh?\n","12691    330  I didn't really understand the concept of deat...\n","2301     488           Never again, no matter what Thorne says.\n","8176     156  - Shall I return after? - That won't be necess...\n","11364     52           Did you pull a knife on me in the night?\n","2059      27  - The boy has lost the use of his legs. - What..."],"text/html":["\n","  <div id=\"df-5f2c5a49-ee72-48ff-9315-14fcdeed9ceb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Number</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5065</th>\n","      <td>407</td>\n","      <td>Shh.</td>\n","    </tr>\n","    <tr>\n","      <th>5352</th>\n","      <td>666</td>\n","      <td>He will.</td>\n","    </tr>\n","    <tr>\n","      <th>12965</th>\n","      <td>578</td>\n","      <td>The world is built by killers.</td>\n","    </tr>\n","    <tr>\n","      <th>1739</th>\n","      <td>648</td>\n","      <td>We've been capturing wildlings, more every month.</td>\n","    </tr>\n","    <tr>\n","      <th>3313</th>\n","      <td>72</td>\n","      <td>- Where's Arya? - At her dancing lessons.</td>\n","    </tr>\n","    <tr>\n","      <th>2441</th>\n","      <td>613</td>\n","      <td>But later when we started to fall...</td>\n","    </tr>\n","    <tr>\n","      <th>9256</th>\n","      <td>54</td>\n","      <td>- I can't lose... - You'll die if she doesn't.</td>\n","    </tr>\n","    <tr>\n","      <th>7847</th>\n","      <td>54</td>\n","      <td>We'll just keep that.</td>\n","    </tr>\n","    <tr>\n","      <th>7337</th>\n","      <td>80</td>\n","      <td>We have enough wheat for a five-year winter.</td>\n","    </tr>\n","    <tr>\n","      <th>11776</th>\n","      <td>204</td>\n","      <td>Ha! The last time the scouts assured us of Sta...</td>\n","    </tr>\n","    <tr>\n","      <th>11049</th>\n","      <td>236</td>\n","      <td>We can't make steel as good as yours, it's tru...</td>\n","    </tr>\n","    <tr>\n","      <th>9866</th>\n","      <td>531</td>\n","      <td>It looked like Stannis.</td>\n","    </tr>\n","    <tr>\n","      <th>13394</th>\n","      <td>388</td>\n","      <td>To create strife between my sister and me.</td>\n","    </tr>\n","    <tr>\n","      <th>3568</th>\n","      <td>282</td>\n","      <td>I deny them,</td>\n","    </tr>\n","    <tr>\n","      <th>5735</th>\n","      <td>410</td>\n","      <td>No, not your death, Khaleesi.</td>\n","    </tr>\n","    <tr>\n","      <th>5439</th>\n","      <td>144</td>\n","      <td>He brought dishonour to our House, but he had ...</td>\n","    </tr>\n","    <tr>\n","      <th>9595</th>\n","      <td>288</td>\n","      <td>He has a good mind for warfare, his men worshi...</td>\n","    </tr>\n","    <tr>\n","      <th>12436</th>\n","      <td>100</td>\n","      <td>It's warm in here.</td>\n","    </tr>\n","    <tr>\n","      <th>8484</th>\n","      <td>433</td>\n","      <td>Dorne is the safest place for her.</td>\n","    </tr>\n","    <tr>\n","      <th>11075</th>\n","      <td>26</td>\n","      <td>They have no value to me missing.</td>\n","    </tr>\n","    <tr>\n","      <th>1747</th>\n","      <td>655</td>\n","      <td>and what lies beyond.</td>\n","    </tr>\n","    <tr>\n","      <th>1839</th>\n","      <td>738</td>\n","      <td>Hup!</td>\n","    </tr>\n","    <tr>\n","      <th>8892</th>\n","      <td>211</td>\n","      <td>You've never married, have you?</td>\n","    </tr>\n","    <tr>\n","      <th>9485</th>\n","      <td>189</td>\n","      <td>I don't hang them for treason.</td>\n","    </tr>\n","    <tr>\n","      <th>8362</th>\n","      <td>323</td>\n","      <td>Matrimony, huh?</td>\n","    </tr>\n","    <tr>\n","      <th>12691</th>\n","      <td>330</td>\n","      <td>I didn't really understand the concept of deat...</td>\n","    </tr>\n","    <tr>\n","      <th>2301</th>\n","      <td>488</td>\n","      <td>Never again, no matter what Thorne says.</td>\n","    </tr>\n","    <tr>\n","      <th>8176</th>\n","      <td>156</td>\n","      <td>- Shall I return after? - That won't be necess...</td>\n","    </tr>\n","    <tr>\n","      <th>11364</th>\n","      <td>52</td>\n","      <td>Did you pull a knife on me in the night?</td>\n","    </tr>\n","    <tr>\n","      <th>2059</th>\n","      <td>27</td>\n","      <td>- The boy has lost the use of his legs. - What...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f2c5a49-ee72-48ff-9315-14fcdeed9ceb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5f2c5a49-ee72-48ff-9315-14fcdeed9ceb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5f2c5a49-ee72-48ff-9315-14fcdeed9ceb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-97452536-973c-4f39-9e75-aade332455a7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97452536-973c-4f39-9e75-aade332455a7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-97452536-973c-4f39-9e75-aade332455a7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"52\",\n          \"100\",\n          \"282\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"- Shall I return after? - That won't be necessary.\",\n          \"He brought dishonour to our House, but he had the grace to leave the sword\",\n          \"I don't hang them for treason.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}],"source":["# Import the libraries needed for preprocessing\n","import re\n","import pandas as pd\n","\n","pattern = r'\"(\\d+)\": \"([^\"]*)\"'\n","\n","# Find all matches\n","matches = re.findall(pattern, got_text)\n","\n","# Create a DataFrame from matches\n","df = pd.DataFrame(matches, columns=['Number', 'Text'])\n","\n","# Generate some samples\n","df.sample(30)"]},{"cell_type":"code","execution_count":4,"id":"41563aa0","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":990},"id":"41563aa0","executionInfo":{"status":"ok","timestamp":1720128006830,"user_tz":-120,"elapsed":1060,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"a0dfb345-430b-4d69-821a-6ddb3b96f714"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Number                                               Text\n","0       1                                         Easy, boy.\n","1      10            Our orders were to track the wildlings.\n","2     100                       - Right. Give it here. - No!\n","3     101                               Put away your blade.\n","4     102  - I take orders from your father, not you. - P...\n","5     103                                   I'm sorry, Bran.\n","6     104                                        Lord Stark?\n","7     105                               There are five pups.\n","8     106                One for each of the Stark children.\n","9     107           The direwolf is the sigil of your house.\n","10    108                      They were meant to have them.\n","11    109                    You will train them yourselves.\n","12     11    We tracked them. They won't trouble us no more.\n","13    110                     You will feed them yourselves.\n","14    111    And if they die, you will bury them yourselves.\n","15    112                                    What about you?\n","16    113                                   I'm not a Stark.\n","17    114                                            Get on.\n","18    115                                        What is it?\n","19    116    The runt of the litter. That one's yours, Snow.\n","20    117  As your brother, I feel it's my duty to warn y...\n","21    118                                you worry too much.\n","22    119  - It's starting to show. - And you never worry...\n","23     12        You don't think he'll ask us how they died?\n","24    120  When we were seven and you jumped off the clif...\n","25    121  100-foot drop into the water... you were never...\n","26    122  There was nothing to be afraid of until you to...\n","27    123                                                   \n","28    124  - What if Jon Arryn told someone? - But who wo...\n","29    125                                        My husband."],"text/html":["\n","  <div id=\"df-bc66b34c-c016-4c35-88d8-383adb6c225f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Number</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Easy, boy.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10</td>\n","      <td>Our orders were to track the wildlings.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100</td>\n","      <td>- Right. Give it here. - No!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>101</td>\n","      <td>Put away your blade.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>102</td>\n","      <td>- I take orders from your father, not you. - P...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>103</td>\n","      <td>I'm sorry, Bran.</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>104</td>\n","      <td>Lord Stark?</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>105</td>\n","      <td>There are five pups.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>106</td>\n","      <td>One for each of the Stark children.</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>107</td>\n","      <td>The direwolf is the sigil of your house.</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>108</td>\n","      <td>They were meant to have them.</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>109</td>\n","      <td>You will train them yourselves.</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>11</td>\n","      <td>We tracked them. They won't trouble us no more.</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>110</td>\n","      <td>You will feed them yourselves.</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>111</td>\n","      <td>And if they die, you will bury them yourselves.</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>112</td>\n","      <td>What about you?</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>113</td>\n","      <td>I'm not a Stark.</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>114</td>\n","      <td>Get on.</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>115</td>\n","      <td>What is it?</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>116</td>\n","      <td>The runt of the litter. That one's yours, Snow.</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>117</td>\n","      <td>As your brother, I feel it's my duty to warn y...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>118</td>\n","      <td>you worry too much.</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>119</td>\n","      <td>- It's starting to show. - And you never worry...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>12</td>\n","      <td>You don't think he'll ask us how they died?</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>120</td>\n","      <td>When we were seven and you jumped off the clif...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>121</td>\n","      <td>100-foot drop into the water... you were never...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>122</td>\n","      <td>There was nothing to be afraid of until you to...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>123</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>124</td>\n","      <td>- What if Jon Arryn told someone? - But who wo...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>125</td>\n","      <td>My husband.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc66b34c-c016-4c35-88d8-383adb6c225f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bc66b34c-c016-4c35-88d8-383adb6c225f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bc66b34c-c016-4c35-88d8-383adb6c225f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-85bffdd2-7ba4-4337-b5fa-6f9a94a75058\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85bffdd2-7ba4-4337-b5fa-6f9a94a75058')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-85bffdd2-7ba4-4337-b5fa-6f9a94a75058 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 13715,\n  \"fields\": [\n    {\n      \"column\": \"Number\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 781,\n        \"samples\": [\n          \"596\",\n          \"588\",\n          \"85\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13018,\n        \"samples\": [\n          \"Moon is goddess - wife of sun.\",\n          \"My son Bran.\",\n          \"and my brother might be the next Hand of the King.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}],"source":["def clean_message(message):\n","    # Remove backslash characters\n","    message = re.sub(r'\\\\', '', message)\n","\n","    # Remove html tags\n","\n","    message = re.sub(r'</?i>', '', message)\n","\n","    return message\n","\n","# Apply the cleaning function to the Message column\n","df['Text'] = df['Text'].apply(clean_message)\n","\n","df.head(30)"]},{"cell_type":"code","execution_count":5,"id":"55d66faa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55d66faa","executionInfo":{"status":"ok","timestamp":1720128014888,"user_tz":-120,"elapsed":524,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"2c597b6a-0108-453e-8bef-7340dff5134e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[['Easy, boy.', 'Our orders were to track the wildlings.'], ['- Right. Give it here. - No!', 'Put away your blade.'], ['- I take orders from your father, not you. - Please, Father!', \"I'm sorry, Bran.\"], ['Lord Stark?', 'There are five pups.'], ['One for each of the Stark children.', 'The direwolf is the sigil of your house.'], ['They were meant to have them.', 'You will train them yourselves.'], [\"We tracked them. They won't trouble us no more.\", 'You will feed them yourselves.'], ['And if they die, you will bury them yourselves.', 'What about you?'], [\"I'm not a Stark.\", 'Get on.'], ['What is it?', \"The runt of the litter. That one's yours, Snow.\"], [\"As your brother, I feel it's my duty to warn you...\", 'you worry too much.'], [\"- It's starting to show. - And you never worry about anything.\", \"You don't think he'll ask us how they died?\"], ['When we were seven and you jumped off the cliffs at Casterly Rock,', '100-foot drop into the water... you were never afraid.'], ['There was nothing to be afraid of until you told Father.', ''], ['- What if Jon Arryn told someone? - But who would he tell?', 'My husband.'], ['If he told the king, both our heads would be skewered on the city gates by now.', \"Whatever Jon Arryn knew or didn't know, it died with him.\"], ['And Robert will choose a new Hand of the King,', \"someone to do his job while he's off fucking boars and hunting whores.\"], ['Get back on your horse.', 'Or is it the other way around?'], ['And life will go on.', 'You should be the Hand of the King.'], [\"That's an honour I can do without.\", 'Their days are too long,'], ['their lives are too short.', 'All these years,'], ['and I still feel like an outsider when I come here.', 'You have five northern children.'], [\"You're not an outsider.\", 'Whatever did it to them could do it to us.'], ['I wonder if the old gods agree.', \"It's your gods with all the rules.\"], ['I am so sorry, my love.', \"- Tell me. - There was a raven from King's Landing.\"], ['Jon Arryn is dead.', 'A fever took him.'], ['I know he was like a father to you.', '- Your sister, the boy? - They both have their health,'], ['gods be good.', 'The raven brought more news.'], ['They even killed the children.', 'The king rides for Winterfell...'], ['with the queen and all the rest of them.', \"If he's coming this far north...\"]]\n"]}],"source":["# Split into message-reply pairs to create a dialogue\n","dialogues = []\n","for i in range(0, len(df) - 1, 2):\n","    message = df.loc[i, 'Text']\n","    reply = df.loc[i + 1, 'Text']\n","    dialogues.append([message, reply])\n","\n","print(dialogues[:30])"]},{"cell_type":"code","execution_count":6,"id":"9d93f89e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d93f89e","executionInfo":{"status":"ok","timestamp":1720128045395,"user_tz":-120,"elapsed":25163,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"f8bc102c-ec38-450f-b312-da87b6fd5a77"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Father,\n","there\n","is\n","only\n","one\n","and\n","he\n","watches\n","over\n","us.\n","<END>\n","<START>\n","things\n","you\n","have\n","not,\n","things\n","I\n","wish\n","I\n","had\n","not.\n","<END>\n","<START>\n","No,\n","I\n","don't\n","believe\n","you\n","have.\n","<END>\n","<START>\n","The\n","dark\n","arts\n","have\n","provided\n","Lord\n","Stannis\n","with\n","his\n","armies\n","<END>\n","<START>\n","For\n","a\n","man\n","in\n","service\n","to\n","such\n","powers\n","to\n","sit\n","on\n","the\n","Iron\n","Throne,\n","<END>\n","<START>\n","And\n","tonight,\n","<END>\n","<START>\n","I\n","believe\n","you\n","are\n","the\n","only\n","man\n","who\n","can\n","stop\n","him.\n","<END>\n","<START>\n","I've\n","never\n","known\n","bells\n","to\n","mean\n","surrender.\n","<END>\n","<START>\n","-\n","Drums.\n","-\n","Drums!\n","<END>\n","<START>\n","The\n","ships\n","are\n","in\n","the\n","bay.\n","<END>\n","<START>\n","-\n","Do\n","you\n","know\n","how\n","to\n","use\n","that?\n","-\n","I\n","chopped\n","wood\n","once.\n","<END>\n","<START>\n","The\n","people\n","of\n","King's\n","Landing\n","did\n","not\n","choose\n","the\n","false\n","king,\n","Joffrey\n","Baratheon.\n","<END>\n","<START>\n","You'll\n","be\n","unstoppable\n","with\n","an\n","axe.\n","<END>\n","<START>\n","-\n","Oh,\n","are\n","we\n","friends\n","now?\n","-\n","Of\n","course\n","we\n","are.\n","<END>\n","<START>\n","Enhances\n","it,\n","really.\n","<END>\n","<START>\n","Been\n","spending\n","time\n","with\n","fancy\n","folks.\n","<END>\n","<START>\n","-\n","Shae.\n","-\n","Shae,\n","yes.\n","<END>\n","<START>\n","Surely\n","my\n","sister\n","has\n","asked\n","you\n","to\n","join\n","the\n","other\n","highborn\n","ladies\n","in\n","Maegor's\n","holdfast.\n","<END>\n","<START>\n","Sansa.\n","<END>\n","<START>\n","Sansa,\n","come\n","here.\n","<END>\n","<START>\n","-\n","Will\n","you?\n","-\n","Just\n","as\n","I\n","pray\n","for\n","the\n","king's.\n","<END>\n","<START>\n","And\n","you,\n","my\n","lion.\n","<END>\n","<START>\n","The\n","tide's\n","against\n","us.\n","<END>\n","<START>\n","You\n","should\n","see\n","him\n","off\n","with\n","a\n","kiss.\n","<END>\n","<START>\n","Hearteater,\n","I've\n","named\n","it.\n","<END>\n","<START>\n","You'll\n","kiss\n","it\n","again\n","when\n","I\n","return\n","<END>\n","<START>\n","Will\n","you\n","slay\n","him\n","yourself?\n","<END>\n","<START>\n","So\n","you'll\n","be\n","outside\n","the\n","gates\n","fighting\n","in\n","the\n","vanguard?\n","<END>\n","<START>\n","Our\n","ships\n","outnumber\n","theirs\n","10-to-1.\n","<END>\n","<START>\n","Of\n","course\n","you'll\n","be\n","in\n","the\n","vanguard.\n","<END>\n","<START>\n","And\n","he\n","is\n","only\n","a\n","pretender.\n","<END>\n","<START>\n","Then\n","you\n","can\n","lick\n","his\n","blood\n","off\n","Hearteater,\n","too.\n","<END>\n","<START>\n","Joffrey\n","will.\n","<END>\n","<START>\n","Come,\n","my\n","lady.\n","<END>\n","<START>\n","Where's\n","our\n","fleet?\n","<END>\n","<START>\n","Why\n","isn't\n","it\n","here\n","now?\n","They're\n","coming.\n","<END>\n","<START>\n","The\n","king\n","has\n","asked\n","you\n","a\n","question.\n","<END>\n","<START>\n","The\n","Hand\n","of\n","the\n","King\n","would\n","like\n","me\n","to\n","tell\n","you\n","to\n","tell\n","the\n","king...\n","<END>\n","<START>\n","That\n","would\n","make\n","me\n","the\n","quarterman.\n","<END>\n","<START>\n","Those\n","walls\n","have\n","never\n","been\n","breached,\n","<END>\n","<START>\n","No\n","signal,\n","no\n","plan.\n","<END>\n","<START>\n","puts\n","your\n","pinched\n","little\n","head\n","atop\n","a\n","gate\n","somewhere.\n","<END>\n","<START>\n","except\n","that\n","my\n","head\n","would\n","be\n","up\n","there,\n","too.\n","<END>\n","<START>\n","but\n","I\n","don't\n","want\n","to\n","see\n","it\n","removed\n","just\n","yet.\n","<END>\n","<START>\n","It\n","was\n","wise\n","to\n","attack\n","at\n","night.\n","We\n","took\n","them\n","by\n","surprise.\n","<END>\n","<START>\n","Lord\n","Varys\n","knows\n","what\n","you\n","had\n","for\n","breakfast\n","three\n","days\n","ago.\n","<END>\n","<START>\n","If\n","it's\n","true\n","there\n","is\n","dissension\n","in\n","their\n","ranks,\n","<END>\n","<START>\n","Maybe.\n","<END>\n","<START>\n","She's\n","always\n","saying\n","how\n","stupid\n","I\n","am.\n","She\n","hates\n","me.\n","<END>\n","<START>\n","I\n","doubt\n","it.\n","<END>\n","<START>\n","when\n","they\n","see\n","you,\n","they\n","don't\n","see\n","a\n","liberator,\n","<END>\n","<START>\n","Sansa.\n","<END>\n","<START>\n","You\n","look\n","pale,\n","child.\n","<END>\n","<START>\n","Yes.\n","<END>\n","<START>\n","The\n","men\n","will\n","bleed\n","out\n","there\n","and\n","you\n","will\n","bleed\n","in\n","here.\n","<END>\n","<START>\n","I'm\n","not\n","thirsty,\n","Your\n","Grace.\n","<END>\n","<START>\n","So?\n","I\n","didn't\n","offer\n","you\n","water.\n","<END>\n","<START>\n","Ser\n","Ilyn?\n","<END>\n","<START>\n","When\n","the\n","axes\n","smash\n","down\n","those\n","doors,\n","you\n","may\n","be\n","glad\n","to\n","have\n","him.\n","<END>\n","<START>\n","Guards\n","we\n","have\n","paid.\n","<END>\n","<START>\n","The\n","lads\n","caught\n","a\n","groom\n","and\n","two\n","maids\n","trying\n","to\n","sneak\n","away\n","<END>\n","<START>\n","I\n","have\n","faith\n","in\n","the\n","Lord\n","of\n","Light.\n","<END>\n","<START>\n","Have\n","Ser\n","Ilyn\n","see\n","to\n","them.\n","<END>\n","<START>\n","The\n","only\n","way\n","to\n","keep\n","the\n","small\n","folk\n","loyal\n","<END>\n","<START>\n","Remember\n","that\n","if\n","you\n","ever\n","hope\n","to\n","become\n","a\n","queen.\n","<END>\n","<START>\n","He\n","is.\n","<END>\n","<START>\n","More\n","wine.\n","<END>\n","<START>\n","There\n","they\n","are.\n","<END>\n","<START>\n","Archers!\n","<END>\n","<START>\n","Nock\n","arrows!\n","<END>\n","<START>\n","What\n","are\n","you\n","doing?\n","We\n","need\n","to\n","attack\n","them.\n","<END>\n","<START>\n","Hold\n","fast!\n","<END>\n","<START>\n","And\n","I\n","have\n","faith\n","in\n","my\n","captain.\n","<END>\n","<START>\n","There's\n","only\n","one\n","ship.\n","<END>\n","<START>\n","Man\n","the\n","below!\n","<END>\n","<START>\n","Draw!\n","<END>\n","<START>\n","Hold.\n","<END>\n","<START>\n","More\n","rocks\n","coming\n","up!\n","<END>\n","<START>\n","Are\n","you\n","afraid,\n","my\n","lion?\n","<END>\n","<START>\n","Wildfire.\n","<END>\n","<START>\n","Matthos!\n","Get\n","down!\n","<END>\n","<START>\n","The\n","dwarf\n","has\n","played\n","his\n","little\n","trick.\n","<END>\n","<START>\n","We're\n","too\n","far\n","from\n","the\n","gates.\n","<END>\n","<START>\n","Hundreds\n","will\n","die.\n","<END>\n","<START>\n","Thousands.\n","<END>\n","<START>\n","Sansa,\n","come\n","here,\n","little\n","dove.\n","<END>\n","<START>\n","What\n","are\n","you\n","doing?\n","<END>\n","<START>\n","You're\n","perfect,\n","aren't\n","you?\n","<END>\n","<START>\n","What\n","are\n","you\n","praying\n","for?\n","<END>\n","<START>\n","Of\n","course\n","I'm\n","afraid.\n","<END>\n","<START>\n","On\n","all\n","of\n","us?\n","<END>\n","<START>\n","Of\n","course,\n","Your\n","Grace.\n","<END>\n","<START>\n","-\n","Joffrey\n","is\n","my...\n","-\n","Oh,\n","shut\n","up,\n","you\n","little\n","fool.\n","<END>\n","<START>\n","The\n","gods\n","have\n","no\n","mercy.\n","That's\n","why\n","they're\n","gods.\n","<END>\n","<START>\n","My\n","mother\n","had\n","just\n","died,\n","you\n","see.\n","<END>\n","<START>\n","I\n","didn't\n","really\n","understand\n","the\n","concept\n","of\n","death,\n","the\n","finality\n","of\n","it.\n","<END>\n","<START>\n","the\n","gods\n","would\n","return\n","my\n","mother\n","to\n","me.\n","I\n","was\n","four.\n","<END>\n","<START>\n","He\n","believes\n","in\n","them,\n","he\n","just\n","doesn't\n","like\n","them\n","very\n","much.\n","<END>\n","<START>\n","Here.\n","<END>\n","<START>\n","Drink.\n","<END>\n","<START>\n","I'm\n","a\n","Lannister.\n","<END>\n","<START>\n","I'd\n","rather\n","face\n","a\n","thousand\n","swords\n","<END>\n","<START>\n","They\n","are\n","your\n","guests\n","under\n","your\n","protection.\n","You\n","asked\n","them\n","here.\n","<END>\n","<START>\n","as\n","it\n","will\n","be\n","of\n","you\n","if\n","you\n","ever\n","become\n","Joffrey's\n","queen.\n","<END>\n","<START>\n","these\n","hens\n","will\n","return\n","to\n","their\n","cocks\n","<END>\n","<START>\n","lifted\n","their\n","spirits.\n","<END>\n","<START>\n","And\n","if\n","the\n","city\n","should\n","fall?\n","<END>\n","<START>\n","The\n","Red\n","Keep\n","should\n","hold\n","for\n","a\n","time,\n","<END>\n","<START>\n","If\n","it\n","were\n","anyone\n","else\n","outside\n","those\n","gates,\n","<END>\n","<START>\n","but\n","this\n","is\n","Stannis\n","Baratheon.\n","<END>\n","<START>\n","Have\n","I\n","shocked\n","you,\n","little\n","dove?\n","<END>\n","<START>\n","But\n","it's\n","not\n","your\n","war.\n","<END>\n","<START>\n","Learn\n","how\n","to\n","use\n","it.\n","Drink.\n","<END>\n","<START>\n","No,\n","you\n","wouldn't,\n","would\n","you?\n","<END>\n","<START>\n","should\n","be\n","in\n","for\n","a\n","bit\n","of\n","a\n","rape.\n","<END>\n","<START>\n","You'll\n","be\n","glad\n","of\n","your\n","red\n","flower\n","then.\n","<END>\n","<START>\n","A\n","precious\n","thing\n","like\n","you\n","will\n","look\n","very,\n","very\n","good.\n","<END>\n","<START>\n","A\n","slice\n","of\n","cake\n","<END>\n","<START>\n","More\n","pressure!\n","<END>\n","<START>\n","Pull!\n","Pull!\n","<END>\n","<START>\n","They're\n","coming.\n","They're\n","coming\n","ashore.\n","<END>\n","<START>\n","Archers!\n","<END>\n","<START>\n","You\n","can't\n","fuck\n","your\n","way\n","out\n","of\n","everything.\n","<END>\n","<START>\n","that\n","manages\n","to\n","touch\n","solid\n","ground.\n","<END>\n","<START>\n","Bring\n","any\n","men\n","guarding\n","it\n","here,\n","now.\n","<END>\n","<START>\n","Let's\n","go.\n","Stannis\n","is\n","sending\n","us\n","fresh\n","meat.\n","<END>\n","<START>\n","Any\n","of\n","these\n","flaming\n","fucking\n","arrows\n","come\n","near\n","me,\n","<END>\n","<START>\n","Pull,\n","pull!\n","Go!\n","<END>\n","<START>\n","Nock!\n","<END>\n","<START>\n","-\n","Draw!\n","-\n","Draw!\n","<END>\n","<START>\n","-\n","Loose!\n","-\n","Loose!\n","<END>\n","<START>\n","-\n","Loose!\n","-\n","Loose!\n","<END>\n","<START>\n","First\n","and\n","second\n","squads,\n","to\n","the\n","gate!\n","To\n","the\n","Mud\n","Gate!\n","<END>\n","<START>\n","She'll\n","blow\n","us\n","straight\n","to\n","the\n","gates.\n","<END>\n","<START>\n","I'll\n","rape\n","his\n","fucking\n","corpse.\n","<END>\n","<START>\n","we\n","looked\n","so\n","much\n","alike\n","even\n","our\n","father\n","couldn't\n","tell\n","us\n","apart.\n","<END>\n","<START>\n","Jaime\n","was\n","taught\n","to\n","fight\n","with\n","sword\n","and\n","lance\n","and\n","mace,\n","<END>\n","<START>\n","and\n","sing\n","and\n","please.\n","<END>\n","<START>\n","and\n","I\n","was\n","sold\n","to\n","some\n","stranger\n","like\n","a\n","horse\n","<END>\n","<START>\n","That\n","I\n","should\n","make\n","love\n","to\n","you\n","like\n","it\n","was\n","your\n","last\n","day\n","on\n","this\n","earth.\n","<END>\n","<START>\n","And\n","you\n","will\n","be\n","Joffrey's.\n","Enjoy.\n","<END>\n","<START>\n","Pretty.\n","<END>\n","<START>\n","Here,\n","it's\n","not\n","difficult.\n","I\n","mastered\n","it\n","when\n","I\n","was\n","four.\n","<END>\n","<START>\n","Better.\n","You\n","learn\n","fast.\n","<END>\n","<START>\n","A\n","few\n","weeks,\n","Your\n","Grace.\n","<END>\n","<START>\n","When\n","did\n","you\n","leave\n","Lorath?\n","<END>\n","<START>\n","But\n","she\n","was\n","a\n","nobleman's\n","daughter.\n","<END>\n","<START>\n","When\n","did\n","you\n","come\n","to\n","Westeros?\n","<END>\n","<START>\n","From\n","Lorathi\n","commoner\n","to\n","the\n","Red\n","Keep\n","in\n","10\n","years,\n","<END>\n","<START>\n","I\n","imagine\n","that's\n","a\n","very\n","interesting\n","story.\n","<END>\n","<START>\n","it\n","is\n","not\n","only\n","the\n","sworn\n","duty\n","of\n","a\n","maester\n","<END>\n","<START>\n","Tell\n","us\n","a\n","story,\n","Shae.\n","<END>\n","<START>\n","Your\n","Grace!\n","<END>\n","<START>\n","The\n","Imp\n","has\n","set\n","the\n","river\n","afire.\n","<END>\n","<START>\n","Stannis'\n","fleet\n","destroyed,\n","but...\n","<END>\n","<START>\n","But\n","his\n","troops\n","have\n","landed\n","outside\n","the\n","city\n","walls.\n","<END>\n","<START>\n","Where\n","is\n","Joffrey?\n","<END>\n","<START>\n","Bring\n","him\n","back\n","inside\n","at\n","once.\n","<END>\n","<START>\n","The\n","king's\n","presence\n","is\n","good\n","for\n","morale.\n","<END>\n","<START>\n","-\n","Not\n","here?\n","-\n","With\n","the\n","women\n","and\n","children?\n","<END>\n","<START>\n","-\n","No,\n","but\n","I...\n","-\n","Now!\n","<END>\n","<START>\n","but\n","also\n","to\n","offer\n","guidance\n","<END>\n","<START>\n","You\n","want\n","to\n","know\n","why\n","he's\n","really\n","here?\n","<END>\n","<START>\n","Stannis\n","may\n","take\n","the\n","city,\n","he\n","may\n","take\n","the\n","throne,\n","<END>\n","<START>\n","Help\n","me!\n","<END>\n","<START>\n","Get\n","the\n","ladders\n","up!\n","<END>\n","<START>\n","Come\n","on,\n","kill\n","the\n","scum!\n","<END>\n","<START>\n","Someone\n","bring\n","me\n","a\n","drink.\n","<END>\n","<START>\n","Can\n","I\n","get\n","you\n","some\n","iced\n","milk\n","<END>\n","<START>\n","Eat\n","shit,\n","dwarf.\n","<END>\n","<START>\n","I\n","lost\n","half\n","my\n","men.\n","<END>\n","<START>\n","Dog,\n","I\n","command\n","you\n","to\n","go\n","back\n","out\n","there\n","and\n","fight.\n","<END>\n","<START>\n","Your\n","words\n","are\n","always\n","wise\n","and\n","measured.\n","<END>\n","<START>\n","Your\n","king's\n","city.\n","<END>\n","<START>\n","Fuck\n","the\n","city.\n","<END>\n","<START>\n","Loose!\n","<END>\n","<START>\n","All\n","right,\n","get\n","up!\n","<END>\n","<START>\n","Clear!\n","<END>\n","<START>\n","Forward!\n","<END>\n","<START>\n","Forward\n","ladders!\n","<END>\n","<START>\n","Heave!\n","<END>\n","<START>\n","the\n","queen\n","has\n","sent\n","me\n","to\n","bring\n","you\n","back\n","to\n","the\n","Red\n","Keep.\n","<END>\n","<START>\n","What\n","would\n","you\n","have\n","me\n","do?\n","<END>\n","<START>\n","a\n","maester's\n","duties\n","become\n","more\n","urgent\n","<END>\n","<START>\n","What\n","did\n","my\n","mother\n","say\n","exactly?\n","Did\n","she\n","have\n","urgent\n","business\n","with\n","me?\n","<END>\n","<START>\n","All\n","men\n","to\n","the\n","battlements!\n","<END>\n","<START>\n","stay\n","with\n","my\n","uncle\n","and\n","represent\n","the\n","king\n","on\n","the\n","field\n","of\n","battle.\n","<END>\n","<START>\n","or\n","I'll\n","kill\n","you\n","myself.\n","<END>\n","<START>\n","No!\n","<END>\n","<START>\n","in\n","times\n","of\n","war\n","and\n","turmoil.\n","<END>\n","<START>\n","We\n","need\n","more\n","arrows!\n","<END>\n","<START>\n","-\n","Why\n","isn't\n","he\n","with\n","us?\n","-\n","Who\n","are\n","we\n","fighting\n","for?\n","<END>\n","<START>\n","I'll\n","lead\n","the\n","attack.\n","<END>\n","<START>\n","-\n","Yes.\n","-\n","What\n","are\n","you\n","talking\n","about?\n","<END>\n","<START>\n","Ser\n","Mandon,\n","you\n","will\n","bear\n","the\n","king's\n","banner.\n","<END>\n","<START>\n","Men,\n","form\n","up.\n","<END>\n","<START>\n","Men!\n","<END>\n","<START>\n","But\n","what\n","does\n","that\n","make\n","the\n","lot\n","of\n","you?\n","<END>\n","<START>\n","And\n","they're\n","at\n","the\n","gates.\n","<END>\n","<START>\n","We'll\n","come\n","out\n","behind\n","them\n","and\n","fuck\n","them\n","in\n","their\n","arses.\n","<END>\n","<START>\n","You\n","brought\n","me\n","something?\n","<END>\n","<START>\n","Don't\n","fight\n","for\n","your\n","king\n","<END>\n","<START>\n","Don't\n","fight\n","for\n","honour.\n","Don't\n","fight\n","for\n","glory.\n","<END>\n","<START>\n","This\n","is\n","your\n","city\n","Stannis\n","means\n","to\n","sack.\n","<END>\n","<START>\n","If\n","he\n","gets\n","in,\n","it\n","will\n","be\n","your\n","houses\n","he\n","burns,\n","<END>\n","<START>\n","your\n","women\n","he\n","will\n","rape.\n","<END>\n","<START>\n","Heave!\n","Heave!\n","<END>\n","<START>\n","Those\n","are\n","brave\n","men\n","knocking\n","at\n","our\n","door.\n","<END>\n","<START>\n","The\n","battle\n","is\n","lost,\n","Your\n","Grace.\n","<END>\n","<START>\n","When\n","the\n","gold\n","cloaks\n","saw\n","the\n","king\n","leaving,\n","<END>\n","<START>\n","Where\n","is\n","my\n","son?\n","<END>\n","<START>\n","Essence\n","of\n","nightshade\n","<END>\n","<START>\n","-\n","Bring\n","me...\n","-\n","Now\n","listen\n","to\n","me...\n","<END>\n","<START>\n","This\n","is\n","the\n","safest\n","place\n","we\n","can\n","be.\n","<END>\n","<START>\n","His\n","knights\n","have\n","rallied\n","behind\n","him.\n","<END>\n","<START>\n","Shall\n","we\n","sing\n","a\n","hymn?\n","<END>\n","<START>\n","Save\n","our\n","sons\n","from\n","war,\n","we\n","pray\n","<END>\n","<START>\n","You\n","must\n","go.\n","<END>\n","<START>\n","Stannis\n","won't\n","hurt\n","you.\n","This\n","one\n","will.\n","<END>\n","<START>\n","The\n","queen\n","said\n","they'd\n","rape\n","everyone.\n","<END>\n","<START>\n","Go.\n","Run.\n","<END>\n","<START>\n","What\n","are\n","you\n","doing\n","here?\n","<END>\n","<START>\n","A\n","single\n","drop\n","in\n","a\n","cup\n","of\n","wine\n","<END>\n","<START>\n","Someplace\n","that\n","isn't\n","burning.\n","<END>\n","<START>\n","Could\n","be.\n","<END>\n","<START>\n","He\n","can\n","die\n","just\n","fine\n","on\n","his\n","own.\n","<END>\n","<START>\n","Take\n","you\n","to\n","Winterfell.\n","<END>\n","<START>\n","Do\n","you\n","want\n","to\n","go\n","home?\n","<END>\n","<START>\n","I'll\n","be\n","safe\n","here.\n","<END>\n","<START>\n","Look\n","at\n","me.\n","<END>\n","<START>\n","The\n","Lannisters\n","are\n","killers.\n","<END>\n","<START>\n","Your\n","brother\n","is\n","a\n","killer.\n","<END>\n","<START>\n","The\n","world\n","is\n","built\n","by\n","killers.\n","<END>\n","<START>\n","Three\n","drops\n","will\n","bring\n","on\n","a\n","deep\n","and\n","dreamless\n","sleep.\n","<END>\n","<START>\n","No,\n","little\n","bird,\n","I\n","won't\n","hurt\n","you.\n","<END>\n","<START>\n","Come\n","on,\n","you\n","bastards!\n","Get\n","up\n","those\n","ladders!\n","<END>\n","<START>\n","Roll\n","it\n","over!\n","<END>\n","<START>\n","Oh,\n","fuck\n","me.\n","<END>\n","<START>\n","Be\n","calm,\n","my\n","sweet.\n","<END>\n","<START>\n","They're\n","still\n","fighting.\n","<END>\n","<START>\n","I'll\n","tell\n","you\n","a\n","story.\n","<END>\n","<START>\n","-\n","They\n","lived\n","in\n","the\n","woods.\n","-\n","The\n","Kingswood?\n","<END>\n","<START>\n","In\n","the\n","Kingswood,\n","there\n","lived\n","a\n","mother\n","and\n","her\n","cub.\n","<END>\n","<START>\n","But\n","there\n","were\n","other\n","things\n","that\n","lived\n","in\n","the\n","woods.\n","Evil\n","things.\n","<END>\n","<START>\n","King's\n","Landing\n","hasn't\n","been\n","home\n","for\n","20\n","years.\n","<END>\n","<START>\n","Like\n","stags.\n","<END>\n","<START>\n","They\n","only\n","eat\n","grass.\n","<END>\n","<START>\n","My\n","lord.\n","<END>\n","<START>\n","The\n","little\n","cub\n","was\n","frightened.\n","<END>\n","<START>\n","<END>\n","<START>\n","Your\n","Grace,\n","if\n","I\n","may\n","ask...\n","<END>\n","<START>\n","<END>\n","<START>\n","<END>\n","<START>\n","And\n","the\n","cub\n","said,\n","<END>\n","<START>\n","<END>\n","<START>\n","I\n","will\n","keep\n","you\n","safe,\n","my\n","love.\n","<END>\n","<START>\n","I\n","promise\n","you.\n","<END>\n","<START>\n","Stand\n","and\n","fight!\n","<END>\n","<START>\n","No!\n","<END>\n","<START>\n","The\n","battle\n","is\n","over.\n","We\n","have\n","won.\n","<END>\n","<START>\n","<END>\n","<START>\n","You\n","must\n","have\n","a\n","lot\n","of\n","work\n","to\n","do.\n","<END>\n","<START>\n","<END>\n","<START>\n","<END>\n","<START>\n","And\n","so\n","he\n","spoke,\n","and\n","so\n","he\n","spoke\n","<END>\n","<START>\n","But\n","now\n","the\n","rains\n","weep\n","o'er\n","his\n","hall\n","<END>\n","<START>\n","Yes,\n","now\n","the\n","rains\n","weep\n","o'er\n","his\n","hall\n","<END>\n","<START>\n","And\n","not\n","a\n","soul\n","to\n","hear\n","<END>\n","<START>\n","Be\n","careful\n","on\n","the\n","stairs,\n","Grand\n","Maester.\n","There\n","are\n","so\n","many.\n","<END>\n","<START>\n","And\n","so\n","he\n","spoke\n","<END>\n","<START>\n","I\n","spent\n","most\n","of\n","my\n","life\n","dodging\n","the\n","royal\n","fleet.\n","<END>\n","<START>\n","With\n","no\n","one\n","there\n","to\n","hear\n","<END>\n","<START>\n","And\n","not\n","a\n","soul\n","to\n","hear\n","<END>\n","<START>\n","Where'd\n","you\n","learn\n","the\n","Lannister\n","song?\n","<END>\n","<START>\n","You've\n","got\n","a\n","pretty\n","voice.\n","<END>\n","<START>\n","And\n","I\n","like\n","your\n","nose.\n","<END>\n","<START>\n","How\n","many\n","times\n","you\n","break\n","it?\n","<END>\n","<START>\n","First\n","time,\n","I\n","was\n","five.\n","<END>\n","<START>\n","It\n","wasn't\n","me\n","she\n","was\n","aiming\n","at.\n","<END>\n","<START>\n","Now\n","he\n","was\n","a\n","real\n","pest.\n","<END>\n","<START>\n","Got\n","in\n","a\n","scrap\n","with\n","a\n","few\n","older\n","boys.\n","<END>\n","<START>\n","This\n","is\n","the\n","royal\n","fleet.\n","<END>\n","<START>\n","Eh,\n","you\n","don't\n","want\n","to\n","know\n","about\n","the\n","third\n","time.\n","<END>\n","<START>\n","Don't\n","feel\n","sorry\n","for\n","him.\n","<END>\n","<START>\n","Welcome,\n","friends.\n","<END>\n","<START>\n","I\n","don't\n","think\n","he\n","likes\n","me.\n","<END>\n","<START>\n","I\n","know\n","it.\n","<END>\n","<START>\n","suffered\n","a\n","stunning\n","defeat\n","at\n","the\n","hands\n","of\n","your\n","father.\n","<END>\n","<START>\n","I\n","would\n","like\n","you\n","<END>\n","<START>\n","Have\n","we\n","met?\n","<END>\n","<START>\n","I\n","meet\n","a\n","lot\n","of\n","men.\n","<END>\n","<START>\n","I\n","think\n","your\n","true\n","talents\n","are\n","wasted\n","on\n","them.\n","<END>\n","<START>\n","Allow\n","me\n","to\n","return\n","the\n","favour.\n","<END>\n","<START>\n","You're\n","afraid.\n","<END>\n","<START>\n","I\n","know\n","who\n","you\n","are.\n","<END>\n","<START>\n","I\n","don't\n","abuse\n","them\n","to\n","satisfy\n","royal\n","whims\n","or\n","force\n","them\n","to\n","abuse\n","each\n","other.\n","<END>\n","<START>\n","I\n","thought\n","you\n","said\n","you\n","knew\n","who\n","I\n","was.\n","<END>\n","<START>\n","Littlefinger\n","looks\n","at\n","you\n","and\n","sees\n","a\n","collection\n","of\n","profitable\n","holes.\n","<END>\n","<START>\n","These\n","are\n","your\n","new\n","chambers.\n","<END>\n","<START>\n","He's\n","a\n","dangerous\n","man.\n","<END>\n","<START>\n","Your\n","current\n","employer\n","hides\n","his\n","very\n","well,\n","<END>\n","<START>\n","You're\n","a\n","virgin,\n","I\n","take\n","it?\n","<END>\n","<START>\n","Childhood\n","must\n","have\n","been\n","awful\n","for\n","you.\n","<END>\n","<START>\n","They\n","laughed\n","at\n","you,\n","called\n","you\n","names?\n","<END>\n","<START>\n","Some\n","boys\n","like\n","a\n","challenge.\n","<END>\n","<START>\n","One\n","or\n","two\n","tried.\n","<END>\n","<START>\n","But\n","you\n","fought\n","them\n","off.\n","<END>\n","<START>\n","overpower\n","you,\n","fling\n","you\n","down,\n","tear\n","off\n","your\n","clothes.\n","<END>\n","<START>\n","-\n","I'm\n","strong\n","enough.\n","-\n","Not\n","interested.\n","<END>\n","<START>\n","You\n","are\n","no\n","longer\n","Hand\n","of\n","the\n","King.\n","<END>\n","<START>\n","<END>\n","<START>\n","Probably\n","served\n","my\n","father's\n","soldiers.\n","<END>\n","<START>\n","That's\n","how\n","they\n","earned\n","this.\n","<END>\n","<START>\n","Must\n","make\n","you\n","proud\n","to\n","serve\n","the\n","Starks.\n","<END>\n","<START>\n","I\n","serve\n","Lady\n","Catelyn.\n","<END>\n","<START>\n","Tell\n","yourself\n","that\n","tonight\n","when\n","they\n","swing\n","in\n","your\n","dreams.\n","<END>\n","<START>\n","We\n","shouldn't\n","stay\n","here.\n","We\n","should\n","get\n","back\n","on\n","the\n","river.\n","<END>\n","<START>\n","I\n","don't\n","care\n","what\n","you\n","think.\n","<END>\n","<START>\n","Untie\n","me.\n","Now!\n","<END>\n","<START>\n","So\n","unless\n","it\n","got\n","stuck\n","in\n","your\n","arse\n","on\n","its\n","way\n","to\n","your\n","cunt,\n","<END>\n","<START>\n","I,\n","Joffrey\n","of\n","the\n","House\n","Baratheon,\n","first\n","of\n","my\n","name,\n","<END>\n","<START>\n","Travelling\n","a\n","prisoner.\n","<END>\n","<START>\n","Well,\n","fuck\n","me!\n","<END>\n","<START>\n","-\n","All\n","right,\n","we'll\n","be\n","going.\n","-\n","Whoa.\n","Whoa!\n","<END>\n","<START>\n","The\n","Starks.\n","<END>\n","<START>\n","-\n","Apparently\n","eating\n","is\n","now\n","a\n","crime.\n","Who\n","knew?\n","-\n","No,\n","stealing\n","is\n","a\n","crime.\n","<END>\n","<START>\n","But\n","it's\n","not\n","a\n","crime\n","to\n","starve.\n","That's\n","justice\n","for\n","you.\n","<END>\n","<START>\n","Why\n","Riverrun?\n","<END>\n","<START>\n","-\n","Why\n","not\n","kill\n","him?\n","-\n","For\n","stealing\n","a\n","pig?\n","<END>\n","<START>\n","He\n","must\n","be\n","important\n","to\n","someone.\n","<END>\n","<START>\n","All\n","right,\n","have\n","it\n","your\n","way,\n","<END>\n","<START>\n","Lord\n","of\n","the\n","Seven\n","Kingdoms\n","and\n","Protector\n","of\n","the\n","Realm,\n","<END>\n","<START>\n","-\n","No.\n","-\n","Then\n","you\n","don't\n","know\n","me.\n","<END>\n","<START>\n","-\n","Is\n","it\n","near\n","Ashemark?\n","-\n","No.\n","<END>\n","<START>\n","What\n","do\n","you\n","think\n","of\n","these\n","beauties?\n","<END>\n","<START>\n","Two\n","of\n","them\n","we\n","did,\n","yeah.\n","<END>\n","<START>\n","I\n","do\n","know\n","you.\n","<END>\n","<START>\n","That's\n","Jaime\n","Lannister.\n","<END>\n","<START>\n","If\n","this\n","is\n","the\n","Kingslayer,\n","I\n","think\n","I'd\n","know\n","about\n","it.\n","<END>\n","<START>\n","I\n","was\n","at\n","Whispering\n","Wood.\n","I\n","saw\n","him.\n","<END>\n","<START>\n","He's\n","not\n","the\n","Kingslayer.\n","Sorry\n","to\n","disappoint\n","you.\n","<END>\n","<START>\n","I\n","have\n","a\n","question\n","for\n","you\n","both.\n","<END>\n","<START>\n","Pod!\n","<END>\n","<START>\n","I\n","count\n","to\n","three,\n","you\n","both\n","answer.\n","<END>\n","<START>\n","One.\n","<END>\n","<START>\n","Two\n","quick\n","deaths.\n","<END>\n","<START>\n","I\n","don't\n","serve\n","the\n","Starks.\n","<END>\n","<START>\n","I\n","told\n","you\n","I'd\n","take\n","you\n","to\n","King's\n","Landing,\n","and\n","that's\n","what\n","I'm\n","going\n","to\n","do.\n","<END>\n","<START>\n","Thank\n","you,\n","Your\n","Grace.\n","<END>\n","<START>\n","I\n","know\n","that.\n","<END>\n","<START>\n","I\n","love\n","her.\n","<END>\n","<START>\n","It\n","is\n","important\n","to\n","me.\n","<END>\n","<START>\n","He\n","hardly\n","knew\n","me\n","or\n","I\n","him.\n","<END>\n","<START>\n","We\n","built\n","it\n","slowly\n","over\n","the\n","years,\n","<END>\n","<START>\n","stone\n","by\n","stone,\n","<END>\n","<START>\n","It's\n","not\n","as\n","exciting\n","as\n","secret\n","passion\n","in\n","the\n","woods,\n","<END>\n","<START>\n","It\n","lasts\n","longer.\n","<END>\n","<START>\n","-\n","what\n","you\n","and\n","father\n","had?\n","-\n","Why\n","not?\n","<END>\n","<START>\n","Because\n","she's\n","not\n","exotic\n","and\n","exciting?\n","<END>\n","<START>\n","For\n","your\n","good\n","service\n","and\n","ingenuity\n","<END>\n","<START>\n","You\n","gave\n","him\n","your\n","word.\n","<END>\n","<START>\n","If\n","your\n","father\n","lived\n","his\n","life\n","for\n","one\n","thing...\n","<END>\n","<START>\n","And\n","the\n","only\n","parent\n","I\n","have\n","left\n","has\n","no\n","right\n","to\n","call\n","anyone\n","reckless.\n","<END>\n","<START>\n","I\n","did.\n","<END>\n","<START>\n","And\n","I'm\n","no\n","better\n","than\n","a\n","savage\n","<END>\n","<START>\n","trusting\n","in\n","a\n","fire\n","god.\n","<END>\n","<START>\n","I\n","led\n","my\n","men\n","to\n","the\n","gates\n","of\n","the\n","seventh\n","hell\n","<END>\n","<START>\n","Attacked\n","from\n","behind\n","by\n","Tywin\n","Lannister\n","and\n","the\n","Tyrells.\n","<END>\n","<START>\n","The\n","Lord\n","of\n","Light\n","only\n","allows\n","me\n","glimpses.\n","<END>\n","<START>\n","Will\n","you\n","quit\n","the\n","war\n","just\n","because\n","you've\n","lost\n","a\n","battle?\n","<END>\n","<START>\n","I\n","declare\n","that\n","you\n","shall\n","be\n","granted\n","the\n","castle\n","of\n","Harrenhal\n","<END>\n","<START>\n","Have\n","you?\n","<END>\n","<START>\n","Show\n","me.\n","<END>\n","<START>\n","Will\n","he\n","save\n","you?\n","<END>\n","<START>\n","Inside\n","you.\n","<END>\n","<START>\n","We\n","murdered\n","him.\n","<END>\n","<START>\n","Share\n","the\n","weight\n","with\n","me.\n","<END>\n","<START>\n","This\n","war\n","has\n","just\n","begun.\n","<END>\n","<START>\n","Thousands\n","will\n","die\n","at\n","your\n","command.\n","<END>\n","<START>\n","You\n","will\n","betray\n","your\n","family.\n","<END>\n","<START>\n","And\n","it\n","will\n","all\n","be\n","worth\n","it\n","<END>\n","<START>\n","to\n","be\n","held\n","by\n","your\n","sons\n","and\n","grandsons\n","from\n","this\n","day\n","until\n","the\n","end\n","of\n","time.\n","<END>\n","<START>\n","You\n","will\n","sweep\n","aside\n","this\n","pretender\n","and\n","that\n","one.\n","<END>\n","<START>\n","You\n","promise\n","these\n","things,\n","<END>\n","<START>\n","None\n","of\n","us\n","know.\n","<END>\n","<START>\n","Look\n","into\n","the\n","fire,\n","my\n","king.\n","<END>\n","<START>\n","-\n","I\n","see\n","fire.\n","-\n","Keep\n","looking.\n","<END>\n","<START>\n","Do\n","you\n","see?\n","<END>\n","<START>\n","Yes.\n","<END>\n","<START>\n","I\n","don't\n","care\n","how\n","many\n","arrows\n","they\n","feather\n","me\n","with,\n","<END>\n","<START>\n","I\n","will\n","kill\n","that\n","horn-blowing\n","cunt\n","before\n","I\n","fall.\n","<END>\n","<START>\n","I\n","know\n","I'm\n","surrounded.\n","<END>\n","<START>\n","I\n","shall\n","have\n","to\n","acquire\n","some\n","sons\n","and\n","grandsons.\n","<END>\n","<START>\n","They\n","don't\n","want\n","you\n","to\n","sleep.\n","<END>\n","<START>\n","Thank\n","you,\n","wise\n","bald\n","man.\n","<END>\n","<START>\n","No\n","word\n","from\n","my\n","father?\n","<END>\n","<START>\n","Send\n","more\n","ravens.\n","<END>\n","<START>\n","The\n","first\n","time\n","I\n","saw\n","Winterfell...\n","<END>\n","<START>\n","Ser\n","Loras\n","Tyrell.\n","<END>\n","<START>\n","it\n","looked\n","like\n","something\n","that\n","had\n","been\n","here\n","for\n","thousands\n","of\n","years\n","<END>\n","<START>\n","I\n","saw\n","it\n","and\n","I\n","thought,\n","<END>\n","<START>\n","<END>\n","<START>\n","Yes,\n","my\n","captors\n","were\n","so\n","very\n","kind\n","to\n","me.\n","You\n","love\n","reminding\n","me\n","of\n","that.\n","<END>\n","<START>\n","You\n","know\n","what\n","it's\n","like\n","to\n","be\n","told\n","how\n","lucky\n","you\n","are\n","to\n","be\n","someone's\n","prisoner?\n","<END>\n","<START>\n","To\n","be\n","told\n","how\n","much\n","you\n","owe\n","them?\n","<END>\n","<START>\n","I\n","will\n","kill\n","that\n","man.\n","<END>\n","<START>\n","the\n","Old\n","Gods,\n","the\n","New\n","Gods,\n","<END>\n","<START>\n","Theon,\n","listen\n","to\n","me.\n","<END>\n","<START>\n","Now\n","Winterfell\n","is\n","yours.\n","<END>\n","<START>\n","The\n","whole\n","realm\n","is\n","in\n","your\n","debt,\n","none\n","more\n","so\n","than\n","I.\n","<END>\n","<START>\n","Run.\n","<END>\n","<START>\n","You\n","can't\n","win.\n","<END>\n","<START>\n","There's\n","nowhere\n","to\n","run.\n","<END>\n","<START>\n","And\n","even\n","if\n","I\n","did,\n","even\n","if\n","by\n","some\n","miracle\n","I\n","slipped\n","through\n","the\n","lines\n","and\n","made\n","it\n","home,\n","<END>\n","<START>\n","The\n","Greyjoy\n","who\n","ran.\n","<END>\n","<START>\n","The\n","shame\n","of\n","the\n","family.\n","<END>\n","<START>\n","Join\n","the\n","Night's\n","Watch.\n","<END>\n","<START>\n","he's\n","beyond\n","reach\n","of\n","the\n","law.\n","<END>\n","<START>\n","I\n","won't\n","make\n","it\n","to\n","the\n","Wall.\n","<END>\n","<START>\n","There\n","are\n","ways.\n","<END>\n","<START>\n","and\n","it\n","shall\n","be\n","yours.\n","<END>\n","<START>\n","But\n","with\n","a\n","little\n","luck...\n","<END>\n","<START>\n","You'll\n","have\n","opportunities\n","there.\n","<END>\n","<START>\n","The\n","opportunity\n","to\n","make\n","amends\n","for\n","what\n","you've\n","done.\n","<END>\n","<START>\n","Things\n","I\n","never\n","imagined\n","myself\n","doing.\n","<END>\n","<START>\n","You're\n","not\n","the\n","man\n","you're\n","pretending\n","to\n","be.\n","<END>\n","<START>\n","Not\n","yet.\n","<END>\n","<START>\n","But\n","I've\n","gone\n","too\n","far\n","to\n","pretend\n","to\n","be\n","anything\n","else.\n","<END>\n","<START>\n","That's\n","the\n","mating\n","call\n","of\n","the\n","Northmen.\n","<END>\n","<START>\n","Well,\n","I\n","haven't\n","had\n","a\n","good\n","fuck\n","in\n","weeks.\n","I'm\n","ready\n","for\n","one.\n","<END>\n","<START>\n","Aye!\n","<END>\n","<START>\n","my\n","sister\n","Margaery,\n","her\n","husband\n","was\n","taken\n","from\n","us\n","before...\n","<END>\n","<START>\n","We\n","die\n","bleeding\n","from\n","100\n","wounds\n","<END>\n","<START>\n","but\n","our\n","war\n","cries\n","will\n","echo\n","through\n","eternity.\n","<END>\n","<START>\n","until\n","the\n","Iron\n","Islands\n","have\n","slipped\n","beneath\n","the\n","waves.\n","<END>\n","<START>\n","and\n","how\n","long\n","we\n","stood.\n","<END>\n","<START>\n","Wex\n","and\n","Urzen,\n","<END>\n","<START>\n","Stygg\n","and\n","Black\n","Lorren.\n","<END>\n","<START>\n","as\n","they\n","leap\n","onto\n","the\n","shores\n","of\n","Seagard\n","and\n","Faircastle.\n","<END>\n","<START>\n","-\n","Mothers\n","will\n","name\n","their\n","sons\n","for\n","us.\n","-\n","Aye!\n","<END>\n","<START>\n","Aye!\n","<END>\n","<START>\n","Aye!\n","<END>\n","<START>\n","I\n","would\n","ask\n","you\n","to\n","find\n","it\n","in\n","your\n","heart\n","to\n","do\n","us\n","the\n","great\n","honour\n","<END>\n","<START>\n","It\n","was\n","a\n","good\n","speech.\n","Didn't\n","want\n","to\n","interrupt.\n","<END>\n","<START>\n","What\n","are\n","you\n","doing?\n","<END>\n","<START>\n","Come\n","on.\n","<END>\n","<START>\n","Why\n","would\n","I\n","lie\n","about\n","it?\n","<END>\n","<START>\n","Where\n","before\n","there\n","was\n","nothing\n","but\n","love.\n","<END>\n","<START>\n","Ser\n","Mandon\n","Moore\n","tried\n","to\n","kill\n","you\n","on\n","your\n","sister's\n","orders.\n","<END>\n","<START>\n","-\n","Pod.\n","-\n","Yes,\n","my\n","lord?\n","<END>\n","<START>\n","-\n","No,\n","my\n","lord.\n","-\n","You're\n","a\n","good\n","lad.\n","<END>\n","<START>\n","I\n","want\n","four\n","of\n","his\n","most\n","loyal\n","gold\n","cloaks\n","outside\n","my\n","door\n","at\n","all\n","times.\n","<END>\n","<START>\n","The\n","gold\n","cloaks\n","are\n","now\n","firmly\n","in\n","the\n","hands\n","of\n","your\n","father\n","or\n","your\n","sister.\n","<END>\n","<START>\n","Tell\n","them\n","I\n","am\n","here\n","with\n","Maester\n","Pycelle.\n","<END>\n","<START>\n","-\n","Then\n","my\n","hill\n","tribesmen.\n","-\n","Have\n","gone\n","home.\n","<END>\n","<START>\n","I'm\n","afraid\n","we\n","won't\n","be\n","seeing\n","each\n","other\n","for\n","some\n","time,\n","my\n","lord.\n","<END>\n","<START>\n","And\n","I\n","thought\n","we\n","were\n","friends.\n","<END>\n","<START>\n","Podrick,\n","would\n","you\n","mind?\n","<END>\n","<START>\n","The\n","king\n","won't\n","give\n","you\n","any\n","honours,\n","<END>\n","<START>\n","With\n","all\n","my\n","heart,\n","Your\n","Grace.\n","<END>\n","<START>\n","Come\n","along\n","now,\n","Podrick.\n","<END>\n","<START>\n","It\n","was\n","good\n","of\n","you\n","to\n","come.\n","<END>\n","<START>\n","-\n","I\n","want\n","to\n","see\n","you.\n","-\n","Believe\n","me,\n","you\n","don't.\n","<END>\n","<START>\n","I\n","will\n","be\n","the\n","first.\n","<END>\n","<START>\n","You\n","are\n","a\n","mess.\n","<END>\n","<START>\n","I'm\n","a\n","monster\n","as\n","well\n","as\n","a\n","dwarf.\n","<END>\n","<START>\n","That\n","was\n","the\n","arrangement\n","we\n","made.\n","<END>\n","<START>\n","Oh.\n","<END>\n","<START>\n","so\n","I\n","make\n","jokes\n","all\n","the\n","time\n","and\n","pay\n","them\n","to\n","laugh.\n","<END>\n","<START>\n","-\n","Let's\n","leave.\n","-\n","Leave?\n","<END>\n","<START>\n","Tales\n","of\n","your\n","courage\n","and\n","wisdom\n","have\n","never\n","been\n","far\n","from\n","my\n","ears.\n","<END>\n","<START>\n","Let's\n","take\n","a\n","boat\n","to\n","Pentos\n","and\n","never\n","come\n","back.\n","<END>\n","<START>\n","Eat,\n","drink,\n","<END>\n","<START>\n","I\n","want\n","to\n","go\n","with\n","you.\n","<END>\n","<START>\n","Your\n","father,\n","your\n","sister,\n","all\n","these\n","bad\n","people,\n","they\n","can't\n","stop\n","you.\n","<END>\n","<START>\n","I\n","can't.\n","<END>\n","<START>\n","I\n","do\n","belong\n","here.\n","<END>\n","<START>\n","Outtalking\n","them,\n","outthinking\n","them.\n","<END>\n","<START>\n","And\n","I\n","like\n","it.\n","<END>\n","<START>\n","Are\n","you\n","going\n","to\n","leave?\n","<END>\n","<START>\n","I\n","am\n","yours\n","and\n","you\n","are\n","mine.\n","<END>\n","<START>\n","I,\n","too,\n","have\n","heard\n","tales\n","of\n","your\n","beauty\n","and\n","grace,\n","<END>\n","<START>\n","binding\n","them\n","as\n","one\n","for\n","eternity.\n","<END>\n","<START>\n","and\n","say\n","the\n","words.\n","<END>\n","<START>\n","-\n","warrior,\n","mother...\n","-\n","warrior,\n","mother...\n","<END>\n","<START>\n","-\n","I\n","am\n","hers\n","and\n","she\n","is\n","mine...\n","-\n","I\n","am\n","his\n","and\n","he\n","is\n","mine...\n","<END>\n","<START>\n","A\n","house\n","of\n","ghosts,\n","Khaleesi.\n","It\n","is\n","known.\n","<END>\n","<START>\n","Where\n","are\n","the\n","guards?\n","<END>\n","<START>\n","Let\n","them\n","try.\n","<END>\n","<START>\n","Khaleesi!\n","<END>\n","<START>\n","Khaleesi!\n","<END>\n","<START>\n","You\n","want\n","me?\n","Here\n","I\n","am.\n","Are\n","you\n","afraid\n","of\n","a\n","little\n","girl?\n","<END>\n","<START>\n","It\n","would\n","be\n","an\n","honour\n","to\n","return\n","your\n","love,\n","<END>\n","<START>\n","How\n","did\n","you\n","know\n","we'd\n","come\n","this\n","way?\n","<END>\n","<START>\n","How\n","did\n","you\n","kill\n","those\n","guards?\n","<END>\n","<START>\n","No\n","harder\n","than\n","taking\n","a\n","new\n","name,\n","if\n","you\n","know\n","the\n","way.\n","<END>\n","<START>\n","-\n","I\n","want\n","to\n","be\n","able\n","to\n","do\n","it,\n","too.\n","-\n","If\n","you\n","would\n","learn,\n","you\n","must\n","come\n","with\n","me.\n","<END>\n","<START>\n","Far\n","and\n","away\n","across\n","the\n","Narrow\n","Sea\n","to\n","Braavos.\n","<END>\n","<START>\n","My\n","dancing\n","master\n","was\n","from\n","Braavos.\n","<END>\n","<START>\n","that\n","is\n","something\n","else\n","entirely.\n","<END>\n","<START>\n","Joffrey,\n","Cersei,\n","Tywin\n","Lannister,\n","<END>\n","<START>\n","Names\n","to\n","offer\n","up\n","to\n","the\n","Red\n","God.\n","<END>\n","<START>\n","I\n","want\n","to.\n","<END>\n","<START>\n","A\n","king\n","must\n","keep\n","his\n","word.\n","<END>\n","<START>\n","And\n","my\n","sister.\n","<END>\n","<START>\n","Then\n","we\n","must\n","part.\n","<END>\n","<START>\n","-\n","Here.\n","-\n","What\n","is\n","it?\n","<END>\n","<START>\n","Could\n","it\n","buy\n","a\n","horse?\n","<END>\n","<START>\n","Then\n","what\n","good\n","is\n","it?\n","<END>\n","<START>\n","Your\n","Grace,\n","<END>\n","<START>\n","just\n","give\n","that\n","coin\n","to\n","any\n","man\n","from\n","Braavos\n","and\n","say\n","these\n","words\n","to\n","him,\n","<END>\n","<START>\n","Valar\n","Morghulis.\n","<END>\n","<START>\n","Jaqen\n","is\n","dead.\n","<END>\n","<START>\n","Valar\n","Morghulis.\n","<END>\n","<START>\n","Farewell,\n","Arya\n","Stark.\n","<END>\n","<START>\n","Osha,\n","what\n","are\n","you\n","doing?\n","<END>\n","<START>\n","-\n","We'll\n","make\n","you\n","better.\n","-\n","I\n","feel\n","just\n","fine.\n","<END>\n","<START>\n","Not\n","everything.\n","Not\n","you.\n","<END>\n","<START>\n","Put\n","on\n","your\n","warmest\n","clothes.\n","<END>\n","<START>\n","North's\n","the\n","wrong\n","way.\n","<END>\n","<START>\n","for\n","you\n","to\n","wed\n","the\n","daughter\n","of\n","a\n","man\n","beheaded\n","for\n","treason,\n","<END>\n","<START>\n","There\n","are\n","too\n","many\n","enemies\n","in\n","the\n","south.\n","<END>\n","<START>\n","He'll\n","look\n","after\n","you\n","and\n","let\n","your\n","mother\n","know\n","you're\n","safe.\n","<END>\n","<START>\n","No\n","more\n","than\n","I\n","want\n","to\n","leave\n","you.\n","<END>\n","<START>\n","Both\n","of\n","you.\n","<END>\n","<START>\n","And\n","for\n","that,\n","I\n","consider\n","myself\n","very,\n","<END>\n","<START>\n","very\n","lucky.\n","<END>\n","<START>\n","I'll\n","be\n","right\n","here.\n","<END>\n","<START>\n","You\n","must\n","protect\n","them.\n","<END>\n","<START>\n","You\n","may\n","have\n","to\n","protect\n","them\n","against\n","your\n","own\n","kind.\n","<END>\n","<START>\n","I'll\n","get\n","you\n","milk\n","of\n","the\n","poppy.\n","<END>\n","<START>\n","For\n","the\n","good\n","of\n","the\n","realm,\n","your\n","councillors\n","beg\n","you\n","<END>\n","<START>\n","Moon\n","of\n","my\n","life.\n","<END>\n","<START>\n","Took\n","you\n","from\n","me\n","before\n","I\n","could\n","even...\n","<END>\n","<START>\n","Maybe\n","I\n","am\n","with\n","you\n","in\n","the\n","Night\n","Lands.\n","<END>\n","<START>\n","Maybe\n","I\n","told\n","the\n","Great\n","Stallion\n","to\n","go\n","fuck\n","himself\n","and\n","came\n","back\n","here\n","to\n","wait\n","for\n","you.\n","<END>\n","<START>\n","Or\n","maybe\n","it\n","is\n","a\n","dream.\n","Your\n","dream,\n","my\n","dream...\n","<END>\n","<START>\n","...I\n","do\n","not\n","know.\n","<END>\n","<START>\n","You\n","are\n","the\n","moon\n","of\n","my\n","life.\n","<END>\n","<START>\n","...and\n","all\n","I\n","need\n","to\n","know.\n","<END>\n","<START>\n","...I\n","will\n","kill\n","the\n","man\n","who\n","tries\n","to\n","wake\n","me.\n","<END>\n","<START>\n","until\n","the\n","rivers\n","run\n","dry\n","<END>\n","<START>\n","-\n","Margaery!\n","-\n","We\n","want\n","Margaery!\n","<END>\n","<START>\n","They\n","want\n","to\n","be\n","with\n","you.\n","<END>\n","<START>\n","You\n","will\n","be.\n","<END>\n","<START>\n","It\n","is\n","strongest\n","in\n","their\n","presence.\n","<END>\n","<START>\n","You\n","will\n","be\n","with\n","them,\n","<END>\n","<START>\n","winter\n","again.\n","<END>\n","<START>\n","Across\n","a\n","thousand,\n","thousand\n","seasons\n","<END>\n","<START>\n","And\n","we\n","will\n","be\n","with\n","you\n","until\n","time\n","comes\n","to\n","an\n","end.\n","<END>\n","<START>\n","This\n","is\n","not\n","my\n","home.\n","<END>\n","<START>\n","They\n","will\n","be\n","waiting\n","a\n","long\n","time.\n","<END>\n","<START>\n","We\n","should\n","be\n","there\n","by\n","sundown.\n","<END>\n","<START>\n","but\n","I\n","took\n","a\n","holy\n","vow.\n","<END>\n","<START>\n","Not\n","talking's\n","not\n","the\n","way\n","to\n","go.\n","<END>\n","<START>\n","You\n","might\n","cut\n","yourself.\n","<END>\n","<START>\n","You\n","look\n","like\n","a\n","baby\n","with\n","a\n","rattle.\n","<END>\n","<START>\n","-\n","Stop!\n","-\n","Why,\n","traitor?\n","<END>\n","<START>\n","Let\n","'em\n","fight.\n","<END>\n","<START>\n","That's\n","it?\n","That's\n","what\n","you\n","can\n","do?\n","<END>\n","<START>\n","Your\n","traitor\n","father\n","teach\n","you\n","that?\n","<END>\n","<START>\n","We\n","are\n","the\n","watchers\n","on\n","the\n","Wall.\n","<END>\n","<START>\n","that's\n","the\n","man\n","who\n","killed\n","Qhorin\n","Halfhand.\n","<END>\n","<START>\n","You\n","don't\n","want\n","this\n","one\n","coming\n","back\n","for\n","you.\n","<END>\n","<START>\n","Yes,\n","my\n","lord.\n","<END>\n","<START>\n","Time\n","to\n","meet\n","the\n","King-beyond-the-Wall.\n","<END>\n","<START>\n","Khaleesi,\n","please.\n","<END>\n","<START>\n","Come.\n","<END>\n","<START>\n","Thank\n","you,\n","Xaro\n","Xhoan\n","Daxos.\n","<END>\n","<START>\n","I\n","am\n","king\n","of\n","Qarth.\n","I\n","can\n","help\n","you\n","now,\n","truly\n","help\n","you.\n","<END>\n","<START>\n","but\n","your\n","father,\n","blessed\n","be\n","his\n","memory,\n","<END>\n","<START>\n","All\n","that\n","you\n","have\n","dreamed\n","is\n","within\n","your\n","reach!\n","<END>\n","<START>\n","-\n","Khaleesi.\n","-\n","Please!\n","Please!\n","<END>\n","<START>\n","It's\n","all\n","a\n","lie.\n","<END>\n","<START>\n","Real\n","enough\n","to\n","buy\n","a\n","ship?\n","<END>\n","<START>\n","Take\n","all\n","the\n","gold\n","and\n","jewels.\n","<END>\n","<START>\n","I\n","thought\n","we\n","were\n","coming\n","north\n","to\n","fight\n","wildlings.\n","<END>\n","<START>\n","It's\n","moose.\n","<END>\n","<START>\n","Well,\n","you\n","see\n","a\n","tree,\n","let\n","me\n","know.\n","<END>\n","<START>\n","the\n","thing\n","about\n","Gilly\n","that's\n","so\n","interesting\n","is...\n","<END>\n","<START>\n","The\n","thing\n","about\n","her\n","that\n","I\n","find\n","so\n","interesting\n","is\n","that\n","after\n","all\n","that\n","Craster's\n","done\n","to\n","her,\n","<END>\n","<START>\n","I\n","have\n","consulted\n","with\n","the\n","High\n","Septon\n","<END>\n","<START>\n","is\n","that\n","she\n","said\n","six\n","words\n","to\n","you.\n","<END>\n","<START>\n","is\n","absolutely\n","nothing.\n","<END>\n","<START>\n","Two\n","blasts\n","is\n","wildlings.\n","<END>\n","<START>\n","Three\n","blasts?\n","<END>\n","<START>\n","Wait!\n","Wait\n","for\n","me!\n","<END>\n","<START>\n","Grenn!\n","<END>\n","<START>\n","free\n","you\n","from\n","any\n","promise\n","you\n","have\n","made\n","to\n","them\n","<END>\n","<START>\n","The\n","gods\n","are\n","good.\n","<END>\n","<START>\n","Ser\n","Loras,\n","I\n","will\n","gladly\n","wed\n","your\n","sweet\n","sister.\n","<END>\n","<START>\n","You\n","will\n","be\n","my\n","queen\n","<END>\n","<START>\n","My\n","lady.\n","<END>\n","<START>\n","They're\n","right.\n","I'm\n","not\n","good\n","enough\n","for\n","him.\n","<END>\n","<START>\n","You'll\n","be\n","good\n","enough\n","for\n","many\n","things.\n","<END>\n","<START>\n","And\n","now\n","that\n","you're\n","a\n","woman,\n","<END>\n","<START>\n","What\n","happened?\n","<END>\n","<START>\n","He'll\n","let\n","you\n","go\n","home?\n","<END>\n","<START>\n","You\n","have\n","a\n","tender\n","heart,\n","just\n","like\n","your\n","mother\n","did\n","at\n","your\n","age.\n","<END>\n","<START>\n","She\n","was\n","like\n","a\n","sister\n","to\n","me.\n","<END>\n","<START>\n","King's\n","Landing\n","is\n","my\n","home\n","now.\n","<END>\n","<START>\n","We're\n","all\n","liars\n","here.\n","<END>\n","<START>\n","And\n","every\n","one\n","of\n","us\n","is\n","better\n","than\n","you.\n","<END>\n","<START>\n","Make\n","yourself\n","comfortable.\n","<END>\n","<START>\n","Here,\n","watch\n","me.\n","<END>\n","<START>\n","Most\n","men\n","like\n","what\n","they\n","see.\n","<END>\n","<START>\n","That's\n","what\n","most\n","men\n","say.\n","<END>\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","\n","\n","#  Building empty lists to hold sentences\n","input_docs = []\n","target_docs = []\n","# Building empty vocabulary sets\n","input_tokens = set()\n","target_tokens = set()\n","\n","for dialogue in dialogues:\n","    if len(dialogue) == 2:\n","        input_doc, target_doc = dialogue\n","        # Appending each input sentence to input_docs\n","        input_docs.append(input_doc)\n","        # Demacate target docs for easy processing\n","        target_doc = \"<START> \" + target_doc + \" <END>\"\n","        # Appending each target sentence to input_docs\n","        target_docs.append(target_doc)\n","  # split up each sentence into words\n","  # and add each unique word to vocabulary set\n","for doc in input_docs:\n","  for token in doc.split():\n","    print(token)\n","    if token not in input_tokens:\n","      input_tokens.add(token)\n","\n","  # Do the same for target_tokens\n","for doc in target_docs:\n","  for token in doc.split():\n","    print(token)\n","    if token not in target_tokens:\n","      target_tokens.add(token)\n","\n","input_tokens = sorted(list(input_tokens))\n","target_tokens = sorted(list(target_tokens))\n","\n","# Create num_encoder_tokens and num_decoder_tokens:\n","num_encoder_tokens = len(input_tokens)        # Number of input tokens\n","num_decoder_tokens = len(target_tokens)       # Number of target tokens"]},{"cell_type":"code","execution_count":7,"id":"ee1a48f2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ee1a48f2","executionInfo":{"status":"ok","timestamp":1720128061843,"user_tz":-120,"elapsed":800,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"06e8bc24-a28f-451c-8470-e56ff8ba4176"},"outputs":[{"output_type":"stream","name":"stdout","text":["24\n","30\n","['#', \"'cause\", \"'em\", \"'em's\", '-', '...22,', '...Lord', '...and', '...did', '...is', '...it', '...moon', '...or', '...poachers,', '...take', '...that', '...the', '...then', '...there', '...to']\n"]}],"source":["# Create max_encoder_seq_length and max_decoder_seq_length. the maximum sentence length in both input and output doc\n","\n","max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n","max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n","\n","print(max_encoder_seq_length)         # Max length of an input sequence\n","print(max_decoder_seq_length)         # Max length a target sequence\n","\n","print(input_tokens[:20])"]},{"cell_type":"code","execution_count":8,"id":"93ecfd45","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93ecfd45","executionInfo":{"status":"ok","timestamp":1720128068532,"user_tz":-120,"elapsed":2395,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"4aeb2068-353f-4084-fe9d-5bbf54463606"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples: 6857\n","Number of unique input tokens: 7548\n","Number of unique output tokens: 7591\n","Max sequence length for inputs: 24\n","Max sequence length for outputs: 30\n"]}],"source":["# Import libraries\n","\n","from tensorflow import keras\n","import numpy as np\n","\n","print('Number of samples:', len(input_docs))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","print('Max sequence length for outputs:', max_decoder_seq_length)"]},{"cell_type":"code","execution_count":9,"id":"a1ec91f2","metadata":{"id":"a1ec91f2","executionInfo":{"status":"ok","timestamp":1720128073340,"user_tz":-120,"elapsed":823,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"outputs":[],"source":["# Create a features dictionary for input_docs\n","input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n","\n","\n","# Build out target_features_dict:\n","target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n","\n","# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_features_dict = dict(\n","    (i, token) for token, i in input_features_dict.items())\n","# Build out reverse_target_features_dict:\n","reverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())"]},{"cell_type":"code","execution_count":10,"id":"3635db4b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3635db4b","executionInfo":{"status":"ok","timestamp":1720128079931,"user_tz":-120,"elapsed":6,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"97773c77-d890-44a7-cbda-2fdb0f8eee47"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Here's the first item in the encoder input matrix:\n"," [[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n","\n","The number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\n"]}],"source":["encoder_input_data = np.zeros(\n","    (len(input_docs), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","print(\"\\nHere's the first item in the encoder input matrix:\\n\", encoder_input_data[0], \"\\n\\nThe number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\")\n","\n","# Build out the decoder_input_data matrix that will hold input sequences:\n","decoder_input_data = np.zeros(\n","    (len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","# Build out the decoder_target_data matrix that will hold target sequences:\n","decoder_target_data = np.zeros(\n","    (len(target_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n"]},{"cell_type":"code","source":["for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n","\n","  for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n","    # Check if the token is in the dictionary before accessing it\n","    if token in input_features_dict:\n","      encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n","\n","  for timestep, token in enumerate(target_doc.split()):\n","\n","    # decoder_target_data is ahead of decoder_input_data by one timestep\n","    if token in target_features_dict:  # Check if the token is in the dictionary\n","      # Assign 1. for the current line, timestep, & word\n","      # in decoder_input_data:\n","      decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n","      if timestep > 0:\n","        # decoder_target_data is ahead by 1 timestep\n","        # and doesn't include the start token.\n","        # Assign 1. for the current line, timestep, & word\n","        # in decoder_target_data:\n","        decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."],"metadata":{"id":"eHH5KazXkziw","executionInfo":{"status":"ok","timestamp":1720128085654,"user_tz":-120,"elapsed":843,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"id":"eHH5KazXkziw","execution_count":11,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","from keras.layers import Input, LSTM, Dense\n","from keras.models import Model\n","\n","# Create the input layer:\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","\n","# Create the LSTM layer:\n","encoder_lstm = LSTM(256, return_state=True)\n","\n","# Retrieve the outputs and states:\n","encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n","\n","# Put the states together in a list:\n","encoder_states = [state_hidden, state_cell]"],"metadata":{"id":"34TJw0wilMHp","executionInfo":{"status":"ok","timestamp":1720128090624,"user_tz":-120,"elapsed":853,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"id":"34TJw0wilMHp","execution_count":12,"outputs":[]},{"cell_type":"code","source":["# The decoder input and LSTM layers:\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","\n","# Retrieve the LSTM outputs and states:\n","decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","\n","# Build a final Dense layer:\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","\n","# Filter outputs through the Dense layer:\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"3sLnHbARnCap","executionInfo":{"status":"ok","timestamp":1720128094104,"user_tz":-120,"elapsed":383,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"id":"3sLnHbARnCap","execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Building the training model:\n","training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","print(\"Model summary:\\n\")\n","training_model.summary()\n","print(\"\\n\\n\")\n","\n","# Compile the model:\n","training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Choose the batch size\n","# and number of epochs:\n","batch_size = 30\n","epochs = 100\n","\n","# Train the model:\n","training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n","print(\"Training the model:\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OH-AG2tnDyk","outputId":"4a1128b9-c655-469e-bfb9-e01fe22ac3ee","executionInfo":{"status":"ok","timestamp":1720137834433,"user_tz":-120,"elapsed":9736563,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"id":"8OH-AG2tnDyk","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model summary:\n","\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, None, 7548)]         0         []                            \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, None, 7591)]         0         []                            \n","                                                                                                  \n"," lstm (LSTM)                 [(None, 256),                7992320   ['input_1[0][0]']             \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," lstm_1 (LSTM)               [(None, None, 256),          8036352   ['input_2[0][0]',             \n","                              (None, 256),                           'lstm[0][1]',                \n","                              (None, 256)]                           'lstm[0][2]']                \n","                                                                                                  \n"," dense (Dense)               (None, None, 7591)           1950887   ['lstm_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 17979559 (68.59 MB)\n","Trainable params: 17979559 (68.59 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","\n","\n","\n","Epoch 1/100\n","183/183 [==============================] - 104s 555ms/step - loss: 1.8680 - accuracy: 0.0342 - val_loss: 1.6957 - val_accuracy: 0.0332\n","Epoch 2/100\n","183/183 [==============================] - 102s 558ms/step - loss: 1.7186 - accuracy: 0.0353 - val_loss: 1.7002 - val_accuracy: 0.0358\n","Epoch 3/100\n","183/183 [==============================] - 107s 583ms/step - loss: 1.7114 - accuracy: 0.0353 - val_loss: 1.6728 - val_accuracy: 0.0342\n","Epoch 4/100\n","183/183 [==============================] - 100s 549ms/step - loss: 1.7074 - accuracy: 0.0350 - val_loss: 1.6776 - val_accuracy: 0.0342\n","Epoch 5/100\n","183/183 [==============================] - 98s 537ms/step - loss: 1.7023 - accuracy: 0.0353 - val_loss: 1.6687 - val_accuracy: 0.0353\n","Epoch 6/100\n","183/183 [==============================] - 98s 535ms/step - loss: 1.6972 - accuracy: 0.0354 - val_loss: 1.7017 - val_accuracy: 0.0347\n","Epoch 7/100\n","183/183 [==============================] - 96s 527ms/step - loss: 1.6920 - accuracy: 0.0353 - val_loss: 1.6796 - val_accuracy: 0.0358\n","Epoch 8/100\n","183/183 [==============================] - 97s 530ms/step - loss: 1.6821 - accuracy: 0.0352 - val_loss: 1.6436 - val_accuracy: 0.0347\n","Epoch 9/100\n","183/183 [==============================] - 95s 520ms/step - loss: 1.6754 - accuracy: 0.0353 - val_loss: 1.7528 - val_accuracy: 0.0334\n","Epoch 10/100\n","183/183 [==============================] - 101s 550ms/step - loss: 1.6690 - accuracy: 0.0352 - val_loss: 1.6924 - val_accuracy: 0.0353\n","Epoch 11/100\n","183/183 [==============================] - 98s 538ms/step - loss: 1.6555 - accuracy: 0.0354 - val_loss: 1.6516 - val_accuracy: 0.0347\n","Epoch 12/100\n","183/183 [==============================] - 95s 519ms/step - loss: 1.6450 - accuracy: 0.0355 - val_loss: 1.6224 - val_accuracy: 0.0358\n","Epoch 13/100\n","183/183 [==============================] - 94s 516ms/step - loss: 1.6373 - accuracy: 0.0354 - val_loss: 1.6190 - val_accuracy: 0.0347\n","Epoch 14/100\n","183/183 [==============================] - 98s 535ms/step - loss: 1.6354 - accuracy: 0.0355 - val_loss: 1.6181 - val_accuracy: 0.0348\n","Epoch 15/100\n","183/183 [==============================] - 100s 545ms/step - loss: 1.6315 - accuracy: 0.0355 - val_loss: 1.6208 - val_accuracy: 0.0348\n","Epoch 16/100\n","183/183 [==============================] - 92s 504ms/step - loss: 1.6223 - accuracy: 0.0357 - val_loss: 1.6355 - val_accuracy: 0.0361\n","Epoch 17/100\n","183/183 [==============================] - 92s 504ms/step - loss: 1.6167 - accuracy: 0.0356 - val_loss: 1.6140 - val_accuracy: 0.0348\n","Epoch 18/100\n","183/183 [==============================] - 99s 539ms/step - loss: 1.6146 - accuracy: 0.0358 - val_loss: 1.6170 - val_accuracy: 0.0349\n","Epoch 19/100\n","183/183 [==============================] - 97s 533ms/step - loss: 1.6210 - accuracy: 0.0358 - val_loss: 1.6143 - val_accuracy: 0.0359\n","Epoch 20/100\n","183/183 [==============================] - 98s 534ms/step - loss: 1.6098 - accuracy: 0.0358 - val_loss: 1.6110 - val_accuracy: 0.0358\n","Epoch 21/100\n","183/183 [==============================] - 97s 532ms/step - loss: 1.6069 - accuracy: 0.0361 - val_loss: 1.6112 - val_accuracy: 0.0353\n","Epoch 22/100\n","183/183 [==============================] - 105s 571ms/step - loss: 1.6051 - accuracy: 0.0360 - val_loss: 1.6121 - val_accuracy: 0.0347\n","Epoch 23/100\n","183/183 [==============================] - 100s 548ms/step - loss: 1.6030 - accuracy: 0.0362 - val_loss: 1.6135 - val_accuracy: 0.0347\n","Epoch 24/100\n","183/183 [==============================] - 104s 571ms/step - loss: 1.6003 - accuracy: 0.0366 - val_loss: 1.6090 - val_accuracy: 0.0355\n","Epoch 25/100\n","183/183 [==============================] - 96s 525ms/step - loss: 1.5984 - accuracy: 0.0373 - val_loss: 1.6074 - val_accuracy: 0.0367\n","Epoch 26/100\n","183/183 [==============================] - 97s 532ms/step - loss: 1.5966 - accuracy: 0.0373 - val_loss: 1.6056 - val_accuracy: 0.0370\n","Epoch 27/100\n","183/183 [==============================] - 98s 536ms/step - loss: 1.5945 - accuracy: 0.0375 - val_loss: 1.6061 - val_accuracy: 0.0369\n","Epoch 28/100\n","183/183 [==============================] - 98s 538ms/step - loss: 1.5933 - accuracy: 0.0378 - val_loss: 1.6044 - val_accuracy: 0.0370\n","Epoch 29/100\n","183/183 [==============================] - 99s 541ms/step - loss: 1.5910 - accuracy: 0.0380 - val_loss: 1.6084 - val_accuracy: 0.0350\n","Epoch 30/100\n","183/183 [==============================] - 102s 556ms/step - loss: 1.5890 - accuracy: 0.0379 - val_loss: 1.6025 - val_accuracy: 0.0371\n","Epoch 31/100\n","183/183 [==============================] - 99s 543ms/step - loss: 1.5869 - accuracy: 0.0382 - val_loss: 1.6058 - val_accuracy: 0.0354\n","Epoch 32/100\n","183/183 [==============================] - 96s 523ms/step - loss: 1.5864 - accuracy: 0.0383 - val_loss: 1.6039 - val_accuracy: 0.0364\n","Epoch 33/100\n","183/183 [==============================] - 97s 530ms/step - loss: 1.5845 - accuracy: 0.0383 - val_loss: 1.6015 - val_accuracy: 0.0360\n","Epoch 34/100\n","183/183 [==============================] - 99s 541ms/step - loss: 1.5818 - accuracy: 0.0385 - val_loss: 1.5986 - val_accuracy: 0.0367\n","Epoch 35/100\n","183/183 [==============================] - 103s 561ms/step - loss: 1.5798 - accuracy: 0.0386 - val_loss: 1.5991 - val_accuracy: 0.0361\n","Epoch 36/100\n","183/183 [==============================] - 103s 562ms/step - loss: 1.5784 - accuracy: 0.0385 - val_loss: 1.6057 - val_accuracy: 0.0372\n","Epoch 37/100\n","183/183 [==============================] - 98s 536ms/step - loss: 1.5768 - accuracy: 0.0387 - val_loss: 1.6006 - val_accuracy: 0.0374\n","Epoch 38/100\n","183/183 [==============================] - 95s 521ms/step - loss: 1.5748 - accuracy: 0.0387 - val_loss: 1.5976 - val_accuracy: 0.0370\n","Epoch 39/100\n","183/183 [==============================] - 99s 541ms/step - loss: 1.5734 - accuracy: 0.0389 - val_loss: 1.6015 - val_accuracy: 0.0362\n","Epoch 40/100\n","183/183 [==============================] - 96s 523ms/step - loss: 1.5720 - accuracy: 0.0387 - val_loss: 1.5955 - val_accuracy: 0.0360\n","Epoch 41/100\n","183/183 [==============================] - 96s 526ms/step - loss: 1.5689 - accuracy: 0.0388 - val_loss: 1.5936 - val_accuracy: 0.0361\n","Epoch 42/100\n","183/183 [==============================] - 99s 541ms/step - loss: 1.5670 - accuracy: 0.0390 - val_loss: 1.6045 - val_accuracy: 0.0357\n","Epoch 43/100\n","183/183 [==============================] - 94s 515ms/step - loss: 1.5651 - accuracy: 0.0392 - val_loss: 1.6109 - val_accuracy: 0.0349\n","Epoch 44/100\n","183/183 [==============================] - 94s 511ms/step - loss: 1.5642 - accuracy: 0.0390 - val_loss: 1.6129 - val_accuracy: 0.0355\n","Epoch 45/100\n","183/183 [==============================] - 97s 528ms/step - loss: 1.5621 - accuracy: 0.0391 - val_loss: 1.5989 - val_accuracy: 0.0362\n","Epoch 46/100\n","183/183 [==============================] - 98s 536ms/step - loss: 1.5591 - accuracy: 0.0393 - val_loss: 1.5896 - val_accuracy: 0.0366\n","Epoch 47/100\n","183/183 [==============================] - 96s 523ms/step - loss: 1.5574 - accuracy: 0.0394 - val_loss: 1.5885 - val_accuracy: 0.0369\n","Epoch 48/100\n","183/183 [==============================] - 98s 538ms/step - loss: 1.5552 - accuracy: 0.0394 - val_loss: 1.5903 - val_accuracy: 0.0361\n","Epoch 49/100\n","183/183 [==============================] - 101s 553ms/step - loss: 1.5527 - accuracy: 0.0394 - val_loss: 1.5972 - val_accuracy: 0.0367\n","Epoch 50/100\n","183/183 [==============================] - 98s 535ms/step - loss: 1.5503 - accuracy: 0.0394 - val_loss: 1.5873 - val_accuracy: 0.0373\n","Epoch 51/100\n","183/183 [==============================] - 98s 538ms/step - loss: 1.5490 - accuracy: 0.0396 - val_loss: 1.6043 - val_accuracy: 0.0364\n","Epoch 52/100\n","183/183 [==============================] - 97s 530ms/step - loss: 1.5586 - accuracy: 0.0389 - val_loss: 1.5823 - val_accuracy: 0.0370\n","Epoch 53/100\n","183/183 [==============================] - 97s 528ms/step - loss: 1.5458 - accuracy: 0.0396 - val_loss: 1.5825 - val_accuracy: 0.0370\n","Epoch 54/100\n","183/183 [==============================] - 97s 528ms/step - loss: 1.5419 - accuracy: 0.0398 - val_loss: 1.5821 - val_accuracy: 0.0375\n","Epoch 55/100\n","183/183 [==============================] - 96s 524ms/step - loss: 1.5414 - accuracy: 0.0400 - val_loss: 1.5825 - val_accuracy: 0.0371\n","Epoch 56/100\n","183/183 [==============================] - 97s 528ms/step - loss: 1.5379 - accuracy: 0.0396 - val_loss: 1.5798 - val_accuracy: 0.0372\n","Epoch 57/100\n","183/183 [==============================] - 97s 532ms/step - loss: 1.5363 - accuracy: 0.0397 - val_loss: 1.5825 - val_accuracy: 0.0368\n","Epoch 58/100\n","183/183 [==============================] - 98s 538ms/step - loss: 1.5335 - accuracy: 0.0399 - val_loss: 1.5789 - val_accuracy: 0.0366\n","Epoch 59/100\n","183/183 [==============================] - 98s 534ms/step - loss: 1.5317 - accuracy: 0.0402 - val_loss: 1.5972 - val_accuracy: 0.0370\n","Epoch 60/100\n","183/183 [==============================] - 100s 545ms/step - loss: 1.5286 - accuracy: 0.0404 - val_loss: 1.5794 - val_accuracy: 0.0371\n","Epoch 61/100\n","183/183 [==============================] - 106s 578ms/step - loss: 1.5253 - accuracy: 0.0406 - val_loss: 1.5784 - val_accuracy: 0.0363\n","Epoch 62/100\n","183/183 [==============================] - 103s 564ms/step - loss: 1.5243 - accuracy: 0.0405 - val_loss: 1.5738 - val_accuracy: 0.0377\n","Epoch 63/100\n","183/183 [==============================] - 99s 540ms/step - loss: 1.5210 - accuracy: 0.0407 - val_loss: 1.5768 - val_accuracy: 0.0365\n","Epoch 64/100\n","183/183 [==============================] - 100s 548ms/step - loss: 1.5190 - accuracy: 0.0410 - val_loss: 1.5733 - val_accuracy: 0.0381\n","Epoch 65/100\n","183/183 [==============================] - 98s 536ms/step - loss: 1.5153 - accuracy: 0.0413 - val_loss: 1.5637 - val_accuracy: 0.0389\n","Epoch 66/100\n","183/183 [==============================] - 105s 573ms/step - loss: 1.5131 - accuracy: 0.0416 - val_loss: 1.5750 - val_accuracy: 0.0376\n","Epoch 67/100\n","183/183 [==============================] - 107s 582ms/step - loss: 1.5101 - accuracy: 0.0416 - val_loss: 1.5616 - val_accuracy: 0.0391\n","Epoch 68/100\n","183/183 [==============================] - 104s 567ms/step - loss: 1.5068 - accuracy: 0.0420 - val_loss: 1.5663 - val_accuracy: 0.0387\n","Epoch 69/100\n","183/183 [==============================] - 98s 534ms/step - loss: 1.5036 - accuracy: 0.0422 - val_loss: 1.5576 - val_accuracy: 0.0391\n","Epoch 70/100\n","183/183 [==============================] - 100s 545ms/step - loss: 1.5009 - accuracy: 0.0424 - val_loss: 1.5570 - val_accuracy: 0.0382\n","Epoch 71/100\n","183/183 [==============================] - 100s 546ms/step - loss: 1.4980 - accuracy: 0.0426 - val_loss: 1.5615 - val_accuracy: 0.0379\n","Epoch 72/100\n","183/183 [==============================] - 102s 560ms/step - loss: 1.4954 - accuracy: 0.0427 - val_loss: 1.5620 - val_accuracy: 0.0399\n","Epoch 73/100\n","183/183 [==============================] - 102s 559ms/step - loss: 1.4928 - accuracy: 0.0429 - val_loss: 1.5539 - val_accuracy: 0.0395\n","Epoch 74/100\n","183/183 [==============================] - 99s 541ms/step - loss: 1.4894 - accuracy: 0.0436 - val_loss: 1.5499 - val_accuracy: 0.0397\n","Epoch 75/100\n","183/183 [==============================] - 96s 526ms/step - loss: 1.4870 - accuracy: 0.0434 - val_loss: 1.5812 - val_accuracy: 0.0398\n","Epoch 76/100\n","183/183 [==============================] - 99s 541ms/step - loss: 1.4838 - accuracy: 0.0439 - val_loss: 1.5494 - val_accuracy: 0.0397\n","Epoch 77/100\n","183/183 [==============================] - 102s 560ms/step - loss: 1.4811 - accuracy: 0.0439 - val_loss: 1.5618 - val_accuracy: 0.0383\n","Epoch 78/100\n","183/183 [==============================] - 102s 560ms/step - loss: 1.4795 - accuracy: 0.0440 - val_loss: 1.5658 - val_accuracy: 0.0395\n","Epoch 79/100\n","183/183 [==============================] - 94s 512ms/step - loss: 1.4763 - accuracy: 0.0443 - val_loss: 1.5474 - val_accuracy: 0.0405\n","Epoch 80/100\n","183/183 [==============================] - 85s 464ms/step - loss: 1.4739 - accuracy: 0.0445 - val_loss: 1.5495 - val_accuracy: 0.0395\n","Epoch 81/100\n","183/183 [==============================] - 84s 458ms/step - loss: 1.4720 - accuracy: 0.0445 - val_loss: 1.5486 - val_accuracy: 0.0402\n","Epoch 82/100\n","183/183 [==============================] - 85s 464ms/step - loss: 1.4691 - accuracy: 0.0446 - val_loss: 1.5449 - val_accuracy: 0.0401\n","Epoch 83/100\n","183/183 [==============================] - 83s 456ms/step - loss: 1.4664 - accuracy: 0.0450 - val_loss: 1.5480 - val_accuracy: 0.0399\n","Epoch 84/100\n","183/183 [==============================] - 84s 458ms/step - loss: 1.4635 - accuracy: 0.0450 - val_loss: 1.5501 - val_accuracy: 0.0397\n","Epoch 85/100\n","183/183 [==============================] - 84s 460ms/step - loss: 1.4615 - accuracy: 0.0450 - val_loss: 1.5501 - val_accuracy: 0.0402\n","Epoch 86/100\n","183/183 [==============================] - 86s 469ms/step - loss: 1.4590 - accuracy: 0.0453 - val_loss: 1.5595 - val_accuracy: 0.0391\n","Epoch 87/100\n","183/183 [==============================] - 91s 496ms/step - loss: 1.4579 - accuracy: 0.0456 - val_loss: 1.5503 - val_accuracy: 0.0404\n","Epoch 88/100\n","183/183 [==============================] - 98s 538ms/step - loss: 1.4544 - accuracy: 0.0455 - val_loss: 1.5463 - val_accuracy: 0.0399\n","Epoch 89/100\n","183/183 [==============================] - 114s 621ms/step - loss: 1.4522 - accuracy: 0.0457 - val_loss: 1.5412 - val_accuracy: 0.0411\n","Epoch 90/100\n","183/183 [==============================] - 106s 579ms/step - loss: 1.4490 - accuracy: 0.0461 - val_loss: 1.5498 - val_accuracy: 0.0409\n","Epoch 91/100\n","183/183 [==============================] - 105s 572ms/step - loss: 1.4471 - accuracy: 0.0465 - val_loss: 1.5383 - val_accuracy: 0.0414\n","Epoch 92/100\n","183/183 [==============================] - 105s 572ms/step - loss: 1.4453 - accuracy: 0.0461 - val_loss: 1.5362 - val_accuracy: 0.0416\n","Epoch 93/100\n","183/183 [==============================] - 103s 562ms/step - loss: 1.4429 - accuracy: 0.0462 - val_loss: 1.5427 - val_accuracy: 0.0412\n","Epoch 94/100\n","183/183 [==============================] - 90s 491ms/step - loss: 1.4405 - accuracy: 0.0463 - val_loss: 1.5457 - val_accuracy: 0.0407\n","Epoch 95/100\n","183/183 [==============================] - 85s 467ms/step - loss: 1.4392 - accuracy: 0.0464 - val_loss: 1.5411 - val_accuracy: 0.0408\n","Epoch 96/100\n","183/183 [==============================] - 87s 473ms/step - loss: 1.4386 - accuracy: 0.0463 - val_loss: 1.5393 - val_accuracy: 0.0413\n","Epoch 97/100\n","183/183 [==============================] - 84s 460ms/step - loss: 1.4344 - accuracy: 0.0465 - val_loss: 1.5446 - val_accuracy: 0.0409\n","Epoch 98/100\n","183/183 [==============================] - 87s 474ms/step - loss: 1.4342 - accuracy: 0.0466 - val_loss: 1.5394 - val_accuracy: 0.0412\n","Epoch 99/100\n","183/183 [==============================] - 86s 468ms/step - loss: 1.4312 - accuracy: 0.0471 - val_loss: 1.5523 - val_accuracy: 0.0403\n","Epoch 100/100\n","183/183 [==============================] - 86s 472ms/step - loss: 1.4290 - accuracy: 0.0470 - val_loss: 1.5447 - val_accuracy: 0.0407\n","Training the model:\n","\n"]}]},{"cell_type":"markdown","source":["When the model was being trained, we implemented teacher forcing where the input sequences were trained side-by-side with their corresponding target sequences. To test the performance of the trained model, we now have to feed our test input sequences and let the trained model do the predicting itself. To do that, we have to create the test model with placeholders for the encoder output states because we do not know what we want to decode yet or what hidden sttates we are going to end up with.\n","\n","We need to do everything step by step.  We need to pass the encoder's final hidden state to the decoder, sample a token, and get the updated hidden state back. Then we'll be able to manually pass the updated hidden state back into the network:"],"metadata":{"id":"AL9obelAl5Z7"},"id":"AL9obelAl5Z7"},{"cell_type":"code","source":["# Build out the test model\n","encoder_inputs = training_model.input[0]\n","encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n","encoder_states = [state_h_enc, state_c_enc]\n","\n","\n","# Building the encoder test model:\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","latent_dim = 256\n","# Building the two decoder state input layers:\n","decoder_state_input_hidden = Input(shape=(latent_dim,))\n","\n","decoder_state_input_cell = Input(shape=(latent_dim,))\n","\n","# Put the state input layers into a list:\n","decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n","\n","# Call the decoder LSTM:\n","decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","\n","decoder_states = [state_hidden, state_cell]\n","# Redefine the decoder outputs:\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Build the decoder test model:\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"],"metadata":{"id":"nABiXVcytNju","executionInfo":{"status":"ok","timestamp":1720138145721,"user_tz":-120,"elapsed":405,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}}},"id":"nABiXVcytNju","execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Create the test function\n","def decode_sequence(test_input):\n","  # Encode the input as state vectors:\n","  encoder_states_value = encoder_model.predict(test_input)\n","  # Set decoder states equal to encoder final states\n","  decoder_states_value = encoder_states_value\n","  # Generate empty target sequence of length 1:\n","  target_seq = np.zeros((1, 1, num_decoder_tokens))\n","\n","  # Populate the first token of target sequence with the start token:\n","  target_seq[0, 0, target_features_dict['<START>']] = 1.\n","\n","  decoded_sentence = ''\n","\n","  stop_condition = False\n","\n","  while not stop_condition:\n","    # Run the decoder model to get possible\n","    # output tokens (with probabilities) & states\n","    output_tokens, new_decoder_hidden_state, new_decoder_cell_state = decoder_model.predict([target_seq] + decoder_states_value)\n","\n","    # Choose token with highest probability\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_token = reverse_target_features_dict[sampled_token_index]\n","\n","    decoded_sentence += \" \" + sampled_token\n","\n","    # Exit condition: either hit max length\n","    # or find stop token.\n","    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n","      stop_condition = True\n","\n","    # Update the target sequence (of length 1).\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, sampled_token_index] = 1.\n","\n","    # Update states\n","    decoder_states_value = [new_decoder_hidden_state,  new_decoder_cell_state]\n","\n","  return decoded_sentence\n","\n","# Test the text generation model.\n","for seq_index in range(10):\n","  test_input = encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(test_input)\n","  print('-')\n","  print('Input sentence:', input_docs[seq_index])\n","  print('Decoded sentence:', decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxI2nGg4tPOl","executionInfo":{"status":"ok","timestamp":1720138161998,"user_tz":-120,"elapsed":5927,"user":{"displayName":"Akisanya Jeremiah","userId":"08459275520907212980"}},"outputId":"4c3ecc54-af71-4cd0-cf3b-4b8465398839"},"id":"xxI2nGg4tPOl","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 384ms/step\n","1/1 [==============================] - 0s 314ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","-\n","Input sentence: Easy, boy.\n","Decoded sentence:  You will have the <END>\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","-\n","Input sentence: - Right. Give it here. - No!\n","Decoded sentence:  I don't have the <END>\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","-\n","Input sentence: - I take orders from your father, not you. - Please, Father!\n","Decoded sentence:  I don't have the <END>\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","-\n","Input sentence: Lord Stark?\n","Decoded sentence:  I don't have the <END>\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 32ms/step\n","-\n","Input sentence: One for each of the Stark children.\n","Decoded sentence:  I don't will a of the of to the\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","-\n","Input sentence: They were meant to have them.\n","Decoded sentence:  I don't have the <END>\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","-\n","Input sentence: We tracked them. They won't trouble us no more.\n","Decoded sentence:  You will have the <END>\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","-\n","Input sentence: And if they die, you will bury them yourselves.\n","Decoded sentence:  I don't have the <END>\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","-\n","Input sentence: I'm not a Stark.\n","Decoded sentence:  I don't have the <END>\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","-\n","Input sentence: What is it?\n","Decoded sentence:  I don't have the <END>\n"]}]},{"cell_type":"markdown","source":["# CONCLUSION\n","\n","The model has been trained and tested, and from the above results it can be observed that the seq2seq model has not learned enough. This could be due to the training times, or it could be a foundational problem as the quality of the dialogues it was provided and also the quantity of the corpus of data. Popularly known language models like llama and gpt are trained with extremely large corpus of data and this is usually possible due to quite high computational capacity.\n","\n","The current language model can be improved upon by adding more training data that help the seq2seq model to perform better, but it would also need a higher capacity than the one currently in use.\n"],"metadata":{"id":"hvZUsIM7_Gva"},"id":"hvZUsIM7_Gva"},{"cell_type":"code","source":[],"metadata":{"id":"DtokC69hBnXH"},"id":"DtokC69hBnXH","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":5}